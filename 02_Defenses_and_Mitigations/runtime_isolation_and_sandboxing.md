---
version: "3.2"
section_type: "defense"
agent: "Principle Engineer"
---
# ğŸ§± Runtime Isolation & Sandboxing

---

## ğŸŒ What Is Runtime Isolation? / Mi az a futÃ¡sidejÅ± izolÃ¡ciÃ³?

**EN:**  
**Runtime isolation** means separating the execution of models, user code, or data flows so that one process cannot interfere with, observe, or compromise another.  
In AI systems, it protects against **code injection, model tampering, data exfiltration**, and **cross-tenant leakage** â€” especially when untrusted code, plugins, or third-party integrations run inside the same environment.  

Put simply: it ensures that *each model or user operates inside its own locked room*, unable to touch others. ğŸ”’ğŸ¤–  

**HU:**  
A **futÃ¡sidejÅ± izolÃ¡ciÃ³** azt jelenti, hogy a modellek, felhasznÃ¡lÃ³i kÃ³dok Ã©s adatfolyamok futtatÃ¡sa egymÃ¡stÃ³l elkÃ¼lÃ¶nÃ­tve tÃ¶rtÃ©nik, Ã­gy egy folyamat nem zavarhatja, figyelheti vagy kompromittÃ¡lhatja a mÃ¡sikat.  
Az MI-rendszerekben ez vÃ©di a rendszert a **kÃ³dbefecskendezÃ©stÅ‘l, modell-manipulÃ¡ciÃ³tÃ³l, adatlopÃ¡stÃ³l** Ã©s a **bÃ©rlÅ‘k kÃ¶zÃ¶tti adatÃ¡tfolyÃ¡stÃ³l** â€” kÃ¼lÃ¶nÃ¶sen akkor, ha nem megbÃ­zhatÃ³ bÅ‘vÃ­tmÃ©nyek vagy harmadik fÃ©l kÃ³djai futnak ugyanabban a kÃ¶rnyezetben.  

EgyszerÅ±en: ez garantÃ¡lja, hogy *minden modell vagy felhasznÃ¡lÃ³ a sajÃ¡t zÃ¡rt szobÃ¡jÃ¡ban mÅ±kÃ¶djÃ¶n*, mÃ¡sokat nem Ã©rintve. ğŸ”’ğŸ¤–  

---

## ğŸ’¡ Why It Matters / MiÃ©rt kritikus

**EN:**  
Modern AI platforms often execute:  
- **User-submitted prompts or code** (e.g. notebooks, Python cells, RAG agents)  
- **Third-party extensions** (e.g. plugins, connectors)  
- **Model pipelines** with shared GPUs or memory  

Without isolation, an attacker could:  
- Escape the execution environment and access host resources  
- Steal API keys or model weights  
- Interfere with other usersâ€™ inference sessions  
- Inject malicious code into memory-shared components  

**HU:**  
A modern MI-platformok gyakran futtatnak:  
- **FelhasznÃ¡lÃ³i promptokat vagy kÃ³dot** (pl. notebookok, Python-cellÃ¡k, RAG-agentek)  
- **Harmadik fÃ©ltÅ‘l szÃ¡rmazÃ³ bÅ‘vÃ­tmÃ©nyeket** (pl. pluginok, connectorok)  
- **Megosztott GPU-val vagy memÃ³riÃ¡val dolgozÃ³ pipeline-okat**  

IzolÃ¡ciÃ³ nÃ©lkÃ¼l a tÃ¡madÃ³ kÃ©pes lehet:  
- KitÃ¶rni a futtatÃ¡si kÃ¶rnyezetbÅ‘l Ã©s hozzÃ¡fÃ©rni a gazdagÃ©p erÅ‘forrÃ¡saihoz  
- API-kulcsokat vagy modell-sÃºlyokat ellopni  
- MÃ¡s felhasznÃ¡lÃ³k inferencia-folyamatait megzavarni  
- RosszindulatÃº kÃ³dot befecskendezni a megosztott komponensekbe  

---

## ğŸ§© Sandboxing Explained / A sandboxolÃ¡s lÃ©nyege

**EN:**  
A **sandbox** is a controlled execution environment that enforces strict boundaries between the running code and the host system.  

Its goals:  
- Restrict system calls (file I/O, networking)  
- Limit memory and CPU consumption  
- Enforce container or VM boundaries  
- Intercept unsafe operations  

### Common Sandbox Technologies:
- **Containers (Docker, Podman)** â€” process-level isolation  
- **Virtual Machines (KVM, Firecracker)** â€” hardware-level isolation  
- **WebAssembly (WASM)** â€” lightweight, language-agnostic sandbox for model plugins  
- **Seccomp / AppArmor / SELinux** â€” syscall-level restrictions  
- **gVisor / Kata Containers** â€” user-space kernel sandboxes for cloud workloads  

**HU:**  
A **sandbox** egy kontrollÃ¡lt futtatÃ¡si kÃ¶rnyezet, amely szigorÃº hatÃ¡rokat szab a futÃ³ kÃ³d Ã©s a gazdagÃ©p kÃ¶zÃ¶tt.  

CÃ©ljai:  
- RendszerhÃ­vÃ¡sok (fÃ¡jl, hÃ¡lÃ³zat) korlÃ¡tozÃ¡sa  
- MemÃ³ria- Ã©s CPU-fogyasztÃ¡s limitÃ¡lÃ¡sa  
- KontÃ©ner- vagy VM-hatÃ¡rok betartÃ¡sa  
- Bizonytalan mÅ±veletek elfogÃ¡sa  

### Gyakori sandbox technolÃ³giÃ¡k:
- **KontÃ©nerek (Docker, Podman)** â€” folyamat-szintÅ± izolÃ¡ciÃ³  
- **VirtuÃ¡lis gÃ©pek (KVM, Firecracker)** â€” hardver-szintÅ± izolÃ¡ciÃ³  
- **WebAssembly (WASM)** â€” kÃ¶nnyÅ±, nyelvfÃ¼ggetlen sandbox modellbÅ‘vÃ­tmÃ©nyekhez  
- **Seccomp / AppArmor / SELinux** â€” rendszerhÃ­vÃ¡s-korlÃ¡tozÃ¡s  
- **gVisor / Kata Containers** â€” felhasznÃ¡lÃ³i tÃ©rben futÃ³ kernel-sandboxok felhÅ‘s kÃ¶rnyezetekhez  

---

## âš™ï¸ Isolation Models in AI Systems / IzolÃ¡ciÃ³s modellek az MI-ben

**EN:**  
1. **Inference Isolation** â€” each model runs in its own container or VM  
2. **GPU Context Isolation** â€” separate CUDA streams, enforce device memory partitioning  
3. **Agent Isolation** â€” each LLM agent or plugin runs in a sandboxed subprocess  
4. **User Session Isolation** â€” tenant-level separation of compute and storage  
5. **Code Execution Isolation** â€” restrict user-provided Python or shell commands in notebooks  

**HU:**  
1. **Inferencia-izolÃ¡ciÃ³** â€” minden modell sajÃ¡t kontÃ©nerben vagy virtuÃ¡lis gÃ©pben fut  
2. **GPU-kontektsus izolÃ¡ciÃ³** â€” kÃ¼lÃ¶n CUDA-szÃ¡lak, memÃ³riarÃ©szek elkÃ¼lÃ¶nÃ­tÃ©se  
3. **Agent-izolÃ¡ciÃ³** â€” minden LLM-agent vagy plugin sandboxolt alfolyamatban fut  
4. **FelhasznÃ¡lÃ³i szekciÃ³ izolÃ¡ciÃ³** â€” bÃ©rlÅ‘nkÃ©nt elkÃ¼lÃ¶nÃ­tett szÃ¡mÃ­tÃ¡si Ã©s tÃ¡rolÃ¡si kÃ¶rnyezet  
5. **KÃ³dfuttatÃ¡s izolÃ¡ciÃ³** â€” felhasznÃ¡lÃ³i Python vagy shell-parancsok korlÃ¡tozÃ¡sa notebookokban  

---

## ğŸ§® Formal Concept / FormÃ¡lis megkÃ¶zelÃ­tÃ©s

**EN:**  
Let \( E_i \) represent the runtime environment of user \( i \).  
For strong isolation, we require:

$$
\forall i \ne j: \; \text{Access}(E_i, E_j) = \varnothing
$$

and for containment under compromise:

$$
\text{Impact}(Compromise(E_i)) \subseteq E_i
$$

Meaning: even if one environment is compromised, its effects are confined within its boundaries.  

**HU:**  
Legyen \( E_i \) a \( i \)-edik felhasznÃ¡lÃ³ futtatÃ¡si kÃ¶rnyezete.  
ErÅ‘s izolÃ¡ciÃ³ esetÃ©n igaz:

$$
\forall i \ne j: \; \text{Access}(E_i, E_j) = \varnothing
$$

Ã©s kompromittÃ¡lÃ¡s esetÃ©n:

$$
\text{Impact}(Compromise(E_i)) \subseteq E_i
$$

Vagyis: mÃ©g ha egy kÃ¶rnyezet kompromittÃ¡lÃ³dik is, a hatÃ¡sa kizÃ¡rÃ³lag abban maradjon.  

---

## ğŸ›¡ï¸ Security Benefits / BiztonsÃ¡gi elÅ‘nyÃ¶k

**EN:**  
- Containment of malicious code or model behavior  
- Protection from privilege escalation  
- Prevention of lateral movement across users or services  
- Safer evaluation of untrusted inputs and plugins  
- Enhanced compliance for multi-tenant cloud environments  

**HU:**  
- RosszindulatÃº kÃ³d vagy modell-viselkedÃ©s elszigetelÃ©se  
- JogosultsÃ¡g-kiterjesztÃ©si tÃ¡madÃ¡sok elleni vÃ©delem  
- OldalirÃ¡nyÃº mozgÃ¡s megakadÃ¡lyozÃ¡sa felhasznÃ¡lÃ³k vagy szolgÃ¡ltatÃ¡sok kÃ¶zÃ¶tt  
- Nem megbÃ­zhatÃ³ inputok Ã©s bÅ‘vÃ­tmÃ©nyek biztonsÃ¡gos tesztelÃ©se  
- MegfelelÅ‘sÃ©g javÃ­tÃ¡sa tÃ¶bb-bÃ©rlÅ‘s felhÅ‘kÃ¶rnyezetekben  

---

## ğŸ”— Integration With Other Defenses / Kapcsolatok mÃ¡s vÃ©delmekkel

**EN:**  
Runtime isolation reinforces:  
- [[model_serving_security|Model Serving Security]] â€” protects APIs and inference nodes  
- [[prompt_injection_and_rag_attacks|Prompt Injection Defense]] â€” confines malicious retrievals  
- [[ai_supply_chain_security|AI Supply Chain Security]] â€” validates runtime provenance  
- [[observability_and_monitoring|Observability & Monitoring]] â€” tracks isolation breaches  
- [[zero_trust|Zero Trust Architecture]] â€” enforces least-privilege at runtime  

**HU:**  
A futÃ¡sidejÅ± izolÃ¡ciÃ³ erÅ‘sÃ­ti:  
- [[model_serving_security|Modell-szolgÃ¡ltatÃ¡s biztonsÃ¡ga]] â€” API-k Ã©s inferencia csomÃ³pontok vÃ©delme  
- [[prompt_injection_and_rag_attacks|Prompt Injection elleni vÃ©delem]] â€” rosszindulatÃº visszakeresÃ©sek elkÃ¼lÃ¶nÃ­tÃ©se  
- [[ai_supply_chain_security|MI-ellÃ¡tÃ¡si lÃ¡nc biztonsÃ¡ga]] â€” futtatÃ¡si eredet validÃ¡lÃ¡sa  
- [[observability_and_monitoring|Observability Ã©s monitoring]] â€” izolÃ¡ciÃ³s megsÃ©rtÃ©sek nyomon kÃ¶vetÃ©se  
- [[zero_trust|Zero Trust architektÃºra]] â€” legkisebb jogosultsÃ¡g futÃ¡sidÅ‘ben  

---

## ğŸ§  Best Practices / Legjobb gyakorlatok

**EN:**  
- Use **container or VM isolation per model** or per user.  
- Enforce **read-only file systems** inside inference sandboxes.  
- Block **outbound network access** except to trusted domains.  
- Monitor **syscalls and resource limits** using AppArmor or Seccomp.  
- Apply **runtime attestation** to verify code integrity (see [[model_watermarking_and_verification|Watermarking & Verification]]).  
- Use **ephemeral sandboxes** that reset after each session.  
- Integrate isolation logs into your [[observability_and_monitoring|Observability Stack]].  

**HU:**  
- HasznÃ¡lj **kontÃ©ner- vagy VM-izolÃ¡ciÃ³t** modellenkÃ©nt vagy felhasznÃ¡lÃ³nkÃ©nt.  
- Ã‰rvÃ©nyesÃ­ts **csak olvashatÃ³ fÃ¡jlrendszert** az inferencia-sandboxokban.  
- Tiltsd a **kimenÅ‘ hÃ¡lÃ³zati hozzÃ¡fÃ©rÃ©st**, kivÃ©ve megbÃ­zhatÃ³ domainekre.  
- Figyeld a **rendszerhÃ­vÃ¡sokat Ã©s erÅ‘forrÃ¡s-hatÃ¡rokat** AppArmor vagy Seccomp segÃ­tsÃ©gÃ©vel.  
- Alkalmazz **futÃ¡sidejÅ± attesztÃ¡ciÃ³t** a kÃ³d integritÃ¡sÃ¡nak ellenÅ‘rzÃ©sÃ©hez (lÃ¡sd [[model_watermarking_and_verification|VÃ­zjelezÃ©s Ã©s verifikÃ¡ciÃ³]]).  
- HasznÃ¡lj **efemer sandboxokat**, amelyek minden munkamenet utÃ¡n tÃ¶rlÅ‘dnek.  
- IntegrÃ¡ld az izolÃ¡ciÃ³s naplÃ³kat az [[observability_and_monitoring|Observability-rendszerbe]].  

---

## âš–ï¸ Trade-offs / Kompromisszumok

**EN:**  
- Strong isolation reduces performance and resource sharing efficiency.  
- Fine-grained sandboxing increases operational complexity.  
- Overly permissive isolation breaks security; overly strict breaks usability.  
- Balancing resource efficiency vs security is a continuous process.  

**HU:**  
- Az erÅ‘s izolÃ¡ciÃ³ csÃ¶kkenti a teljesÃ­tmÃ©nyt Ã©s a megosztott erÅ‘forrÃ¡sok hatÃ©konysÃ¡gÃ¡t.  
- A finomszemcsÃ©s sandboxolÃ¡s nÃ¶veli az Ã¼zemeltetÃ©si komplexitÃ¡st.  
- A tÃºl megengedÅ‘ izolÃ¡ciÃ³ gyengÃ­ti a vÃ©delmet, a tÃºl szigorÃº pedig rontja a hasznÃ¡lhatÃ³sÃ¡got.  
- Az erÅ‘forrÃ¡s-hatÃ©konysÃ¡g Ã©s biztonsÃ¡g kÃ¶zÃ¶tti egyensÃºly folyamatos kihÃ­vÃ¡s.  

---

## ğŸ§­ Review Questions / EllenÅ‘rzÅ‘ kÃ©rdÃ©sek

1. Define runtime isolation and explain how it differs from static sandboxing.  
2. What are the main attack vectors mitigated by sandboxing in AI inference environments?  
3. Compare container-based and VM-based isolation in terms of security vs performance.  
4. How can runtime attestation strengthen sandbox integrity?  
5. Design a sandboxing strategy for a multi-tenant RAG system using external connectors.  

---

> â€œIn AI security, true trust is built on isolation â€” not assumptions.â€ ğŸ§±
