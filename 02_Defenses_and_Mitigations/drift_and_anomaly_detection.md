# Drift & Anomaly Detection in AI Systems ğŸ“‰

_Catching misbehavior before it becomes an incident â€“ bilingual educational version (HU + EN)_

---

AI models donâ€™t break like classic software.  
They **slowly slide** out of alignment: data changes, user behavior shifts, attackers adapt, and suddenly the model is making decisions that _used to be_ correct, but now are subtly wrong.

This slow slide is called **drift** â€” and if you donâ€™t detect it, it silently becomes an **incident**.  
Ez a fejezet arrÃ³l szÃ³l, hogyan ismerd fel, ha a modelled _eltÃ¡volodik a valÃ³sÃ¡gtÃ³l_ vagy a biztonsÃ¡gos mÅ±kÃ¶dÃ©stÅ‘l, Ã©s hogyan Ã¡llÃ­tsd meg, mielÅ‘tt kÃ¡rt okozna.

---

## ğŸ§­ What is Drift? â€“ Mi az a drift?

**EN:**  
In AI, **drift** means that the world the model sees has changed compared to the world it was trained on.  
The model is still â€œcorrectâ€ _relative to its training data_, but that data is no longer representative of current reality.

**Types of drift youâ€™ll meet in practice:**

- **Data (input) drift:** the distribution of incoming inputs changes.
    
- **Label (target) drift:** the relationship between features and labels changes (e.g., fraud patterns evolve).
    
- **Concept drift:** the underlying meaning of â€œright vs wrongâ€ changes (e.g., new regulations or business rules).
    

**HU:**  
AI-ban **driftnek** azt nevezzÃ¼k, amikor a modell **mÃ¡s vilÃ¡got lÃ¡t**, mint amire tanÃ­tottuk.  
A modell a sajÃ¡t trÃ©ning-adatÃ¡hoz kÃ©pest mÃ©g â€okÃ©â€, csak Ã©pp a valÃ³sÃ¡g ment el mellette.

**A legfontosabb drift-tÃ­pusok:**

- **Adat (input) drift:** megvÃ¡ltozik a beÃ©rkezÅ‘ adatok eloszlÃ¡sa.
    
- **Label (target) drift:** a bemenetâ€“kimenet kapcsolat vÃ¡ltozik (pl. Ãºj csalÃ¡si mintÃ¡k).
    
- **Koncept drift:** maga a _â€mi a jÃ³ dÃ¶ntÃ©sâ€_ vÃ¡ltozik (jogszabÃ¡ly, Ã¼zleti szabÃ¡ly, etikai elv).
    

ğŸ’¡ _Drift is not a bug â€” itâ€™s the world moving while your model stands still._

---

## ğŸš¨ Why Drift is a Security & Safety Problem

**EN:**  
Drift is not only a â€œdata scienceâ€ concern â€” itâ€™s a **security and safety** concern:

- A fraud model with drift can start **approving fraud**.
    
- A content filter with drift might miss **toxic or extremist content**.
    
- A medical triage model with drift can misprioritize patients.
    

Attackers can even **weaponize drift**:

- By slowly injecting poisoned inputs over time ([[data_poisoning_attacks|Data Poisoning Attacks]]).
    
- By exploiting changes in user behavior to trigger misclassifications.
    

**HU:**  
A drift nem csak adatkutatÃ³i problÃ©ma â€” **biztonsÃ¡gi Ã©s safety-kÃ©rdÃ©s**:

- Ha driftes a csalÃ¡sdetektÃ¡lÃ³ modell, elkezd **tÃ©vesen jÃ³vÃ¡hagyni csalÃ¡sokat**.
    
- Ha driftes a tartalomszÅ±rÅ‘, nem veszi Ã©szre a **toxikus / szÃ©lsÅ‘sÃ©ges tartalmakat**.
    
- Ha driftes az orvosi modell, **rossz pÃ¡cienst rangsorol elÅ‘re vagy hÃ¡tra**.
    

A tÃ¡madÃ³k akÃ¡r **szÃ¡ndÃ©kosan is generÃ¡lhatnak driftet**:  
lassan adagolt mÃ©rgezÅ‘ inputokkal, szokatlan mintÃ¡kkal, amelyek kicsÃºsztatjÃ¡k a modellt az ideÃ¡lis mÅ±kÃ¶dÃ©sbÅ‘l.

---

## ğŸ§  Anomaly Detection vs Drift Detection

**EN:**  
Although related, **drift** and **anomalies** are not the same:

- Drift = _systematic_ shift of the whole distribution.
    
- Anomaly = _local_ weirdness (outliers, spikes, unexpected events).
    

You need both:

- **[[drift_and_anomaly_detection|Drift Detection]]** to see the long-term trend.
    
- **Anomaly Detection** to spot sudden, suspicious events (e.g., a burst of adversarial queries).
    

**HU:**  
BÃ¡r kapcsolÃ³dnak, a **drift** Ã©s az **anomÃ¡lia** nem ugyanaz:

- Drift = _rendszerszintÅ±_ eltolÃ³dÃ¡s az idÅ‘k sorÃ¡n.
    
- AnomÃ¡lia = _helyi_ furcsasÃ¡g â€” kiugrÃ³ pont, szokatlan esemÃ©ny.
    

MindkettÅ‘re szÃ¼ksÃ©g van:

- **Drift DetektÃ¡lÃ¡s**: hosszÃº tÃ¡vÃº elcsÃºszÃ¡s figyelÃ©se
    
- **AnomÃ¡lia DetektÃ¡lÃ¡s**: hirtelen, gyanÃºs tÃ¶rtÃ©nÃ©sek (pl. tÃ¡madÃ¡si prÃ³bÃ¡lkozÃ¡s-csÃºcs) felismerÃ©se
    

---

## ğŸ§© Where to Monitor for Drift & Anomalies

**EN:**  
You can (and should) monitor multiple layers of your AI system:

1. **Input Level:**
    
    - Monitor the distribution of incoming data: feature ranges, categorical frequencies, language, source.
        
    - Catch abnormal spikes: weird tokens, repeated prompts, suspicious IP ranges.
        
2. **Model Output Level:**
    
    - Track predicted classes, probabilities, and calibration over time.
        
    - Monitor toxicity scores, bias indicators, hallucination likelihood (for LLMs).
        
3. **Behavior Level (Systems & Users):**
    
    - Monitor user behavior: error reports, manual overrides, escalations.
        
    - Monitor downstream system impact: chargebacks, safety complaints, legal incidents.
        

**HU:**  
Driftet Ã©s anomÃ¡liÃ¡t tÃ¶bb rÃ©tegen kell figyelni:

1ï¸âƒ£ **Bemeneti szint:**

- Az Ã©rkezÅ‘ adatok eloszlÃ¡sa, tartomÃ¡nya, tÃ­pusa, forrÃ¡sa
    
- Szokatlan tÃ¼skÃ©k: fura tokenek, ismÃ©tlÅ‘dÅ‘ promptok, gyanÃºs IP-tartomÃ¡nyok
    

2ï¸âƒ£ **Modell kimeneti szint:**

- PredikÃ¡lt osztÃ¡lyok eloszlÃ¡sa, valÃ³szÃ­nÅ±sÃ©gek, kalibrÃ¡ciÃ³
    
- ToxicitÃ¡s, torzÃ­tÃ¡s-mutatÃ³k, LLM-eknÃ©l a hallucinÃ¡ciÃ³ gyanÃºja
    

3ï¸âƒ£ **ViselkedÃ©si szint (felhasznÃ¡lÃ³ + rendszer):**

- FelhasznÃ¡lÃ³i panaszok, manuÃ¡lis felÃ¼lbÃ­rÃ¡lÃ¡sok, eszkalÃ¡ciÃ³k
    
- Ãœzleti mutatÃ³k: chargeback, safety-incident, compliance-riasztÃ¡sok szÃ¡ma
    

ğŸ¯ _If you only watch accuracy on a test set, you are blind to real-world drift._

---

## ğŸ§ª Techniques for Drift Detection

**EN:**  
Common techniques include:

- **Statistical Distance Metrics:**  
    Compare new data to training data using KL divergence, Jensenâ€“Shannon divergence, Kolmogorovâ€“Smirnov tests, etc.
    
- **Population Stability Index (PSI):**  
    Widely used in finance; measures how much a feature distribution has shifted.
    
- **Embedding-based Drift:**  
    For text/image models, compute embeddings and monitor shifts in embedding space instead of raw tokens or pixels.
    
- **Performance Drift:**  
    Monitor business KPIs and ground truth where available: increased error rates, fewer true positives, more false negatives.
    

**HU:**  
Elterjedt drift-detektÃ¡lÃ¡si mÃ³dszerek:

- **Statisztikai tÃ¡volsÃ¡gok:**  
    Az Ãºj Ã©s rÃ©gi adat eloszlÃ¡sainak Ã¶sszehasonlÃ­tÃ¡sa (KL-divergencia, JS-divergencia, KS-teszt stb.).
    
- **PSI (Population Stability Index):**  
    FÅ‘leg pÃ©nzÃ¼gyben hasznÃ¡ljÃ¡k; azt mÃ©ri, mennyire tÃ©rt el egy vÃ¡ltozÃ³ eloszlÃ¡sa a referenciÃ¡tÃ³l.
    
- **Embedding-alapÃº drift:**  
    SzÃ¶veg- Ã©s kÃ©palapÃº modelleknÃ©l az embedding-tÃ©rben figyeljÃ¼k a vÃ¡ltozÃ¡st, nem a nyers tokeneket vagy pixeleket.
    
- **TeljesÃ­tmÃ©ny-drift:**  
    Ãœzleti vagy ground-truth mutatÃ³k romlÃ¡sa: tÃ¶bb hiba, kevesebb helyes talÃ¡lat, tÃ¶bb panasz.
    

---

## ğŸ” Techniques for Anomaly Detection

**EN:**  
For anomalies, we usually care about **rare, suspicious patterns**:

- Unusually high number of failed logins / API calls
    
- Sudden spike in â€œjailbreakâ€ prompts to an LLM
    
- Highly unusual input combinations (never seen before in training)
    

Techniques include:

- **Rule-based detectors:** simple thresholds, regex, allowlists/denylists.
    
- **Unsupervised models:** Isolation Forest, One-Class SVM, autoencoders on embeddings.
    
- **Hybrid:** rules + ML to reduce false positives.
    

**HU:**  
AnomÃ¡liÃ¡knÃ¡l a **ritka, gyanÃºs mintÃ¡kra** vadÃ¡szunk:

- Hirtelen megugrÃ³ sikertelen belÃ©pÃ©sek
    
- Prompt injection kÃ­sÃ©rletek â€hullÃ¡maiâ€ LLM-eknÃ©l
    
- Olyan bemenetek, amelyeket a trÃ©ningadat sosem lÃ¡tott egyÃ¼tt
    

AlkalmazhatÃ³ technikÃ¡k:

- **SzabÃ¡lyalapÃº detektÃ¡lÃ¡s:** kÃ¼szÃ¶bÃ©rtÃ©kek, regex, allow/deny listÃ¡k
    
- **FelhÃ¼gyelet nÃ©lkÃ¼li modellek:** Isolation Forest, One-Class SVM, autoencoder az embedding-tÃ©rben
    
- **Hibrid megoldÃ¡sok:** a szabÃ¡lyok Ã©s ML kombinÃ¡lÃ¡sa a hamis pozitÃ­vak csÃ¶kkentÃ©sÃ©re
    

---

## ğŸ›°ï¸ Observability for AI â€“ lÃ¡thatÃ³vÃ¡ tenni a lÃ¡thatatlant

**EN:**  
Drift and anomaly detection live inside a broader practice: **[[observability_and_monitoring|Observability and Monitoring]]** for AI.  
This includes:

- Centralized logging of inputs, outputs, and metadata
    
- Model-version tracking ([[ai_model_provenance_and_lineage|Provenance & Lineage]])
    
- Correlation with infrastructure metrics (CPU, GPU, memory, latency)
    
- Linking alerts to [[incident_response_for_ai|Incident Response Playbooks]]
    

**HU:**  
A drift- Ã©s anomÃ¡lia-detektÃ¡lÃ¡s az **AI Observability** rÃ©sze.  
Ide tartozik:

- Bemenetek, kimenetek Ã©s metaadatok kÃ¶zpontosÃ­tott naplÃ³zÃ¡sa
    
- ModellverziÃ³k Ã©s lineage nyomon kÃ¶vetÃ©se
    
- InfrastruktÃºra-metrikÃ¡k (CPU, GPU, memÃ³ria, latency) korrelÃ¡lÃ¡sa a modellviselkedÃ©ssel
    
- RiasztÃ¡sok kapcsolÃ¡sa az [[incident_response_for_ai|AI IncidenskezelÃ©si]] playbookokhoz
    

ğŸ’¡ _You canâ€™t detect what you donâ€™t log â€” and you shouldnâ€™t log what you canâ€™t protect._

---

## ğŸ”„ Drift Detection as Part of the Lifecycle

**EN:**  
Drift detection isnâ€™t a one-off task â€” itâ€™s embedded into the **AI lifecycle**:

1. **During Design:**
    
    - Identify which features are most sensitive to drift.
        
    - Decide what â€œnormal behaviorâ€ looks like and how to measure it.
        
2. **During Deployment:**
    
    - Enable logging and metrics from day one.
        
    - Set initial thresholds and alerts based on training data.
        
3. **During Operation:**
    
    - Continuously compare live data to reference distributions.
        
    - Trigger retraining / human review when drift crosses thresholds.
        
4. **During Governance Reviews:**
    
    - Use drift reports as input to [[ai_risk_assessment_methodology|Risk Assessments]].
        
    - Document decisions to retrain, rollback, or retire models.
        

**HU:**  
A drift-detektÃ¡lÃ¡s nem egy kÃ¼lÃ¶n feladat, hanem az **AI-Ã©letciklus rÃ©sze**:

1ï¸âƒ£ **TervezÃ©skor:**

- AzonosÃ­tsd, mely feature-Ã¶k Ã©rzÃ©kenyek a driftre.
    
- DÃ¶ntsd el, hogy mi szÃ¡mÃ­t â€normÃ¡lis mÅ±kÃ¶dÃ©snekâ€, Ã©s hogyan mÃ©red.
    

2ï¸âƒ£ **BevetÃ©skor:**

- MÃ¡r az elsÅ‘ naptÃ³l legyen naplÃ³zÃ¡s Ã©s metrika.
    
- ÃllÃ­ts be kezdÅ‘ kÃ¼szÃ¶bÃ¶ket a trÃ©ningadat alapjÃ¡n.
    

3ï¸âƒ£ **ÃœzemeltetÃ©s kÃ¶zben:**

- Folyamatosan hasonlÃ­tsd Ã¶ssze a live adatot a referenciÃ¡val.
    
- KÃ¼szÃ¶b Ã¡tlÃ©pÃ©sekor indÃ­ts retraininget vagy emberi review-t.
    

4ï¸âƒ£ **Governance-reviewk sorÃ¡n:**

- HasznÃ¡ld a drift-jelentÃ©seket a kockÃ¡zatelemzÃ©s rÃ©szekÃ©nt.
    
- DokumentÃ¡ld, mikor, miÃ©rt Ã©s hogyan tanÃ­tottad Ãºjra vagy vontad vissza a modellt.
    

---

## ğŸ§¯ Linking Drift to Incident Response

**EN:**  
Sometimes drift is slow and harmless.  
Other times, itâ€™s a **pre-incident signal**.

Thatâ€™s why your drift detection must integrate with:

- **[[incident_response_for_ai|AI Incident Response]]** (automatic case creation when thresholds are exceeded)
    
- **[[red_teaming_and_simulation|Red Teaming & Simulation]]** (test whether drift makes attacks easier)
    
- **[[ai_security_metrics_and_kpis|Security Metrics & KPIs]]** (drift indicators as leading risk signals)
    

**HU:**  
A drift nÃ©ha Ã¡rtalmatlan, mÃ¡skor **kÃ¶zelgÅ‘ incidens elÅ‘jele**.  
EzÃ©rt a drift-detektort Ã¶ssze kell kÃ¶tni:

- az **AI IncidenskezelÃ©ssel** (kÃ¼szÃ¶b Ã¡tlÃ©pÃ©se â†’ ticket, eszkalÃ¡ciÃ³)
    
- a **Red Teaminggel** (meg kell nÃ©zni, a drift nem kÃ¶nnyÃ­ti-e meg a tÃ¡madÃ¡st)
    
- a **Security KPI-kkel** (a drift a kockÃ¡zat nÃ¶vekedÃ©sÃ©t jelzÅ‘ korai mutatÃ³ lehet)
    

ğŸ¯ _Think of drift alerts as smoke detectors â€” not every alarm means fire, but you never ignore them._

---

## ğŸ§  Practical Example â€“ Fraud Detection Model

**EN:**  
A bank uses a model to detect fraud.  
For months, performance is stable â€” then the drift dashboard shows:

- More transactions at night
    
- New geographic clusters
    
- Less frequent use of older payment methods
    

The modelâ€™s accuracy on recent labeled data starts to fall.  
At the same time, chargebacks increase.

Actions:

- Investigate feature drift and concept drift
    
- Retrain the model with recent data
    
- Update [[model_certification_and_testing|Certification Tests]]
    
- Adjust threshold and guardrails
    

**HU:**  
Egy bank csalÃ¡sdetektÃ¡lÃ³ modellt hasznÃ¡l.  
HÃ³napokig stabil, majd a drift-dashboard ezt mutatja:

- tÃ¶bb Ã©jszakai tranzakciÃ³,
    
- Ãºj fÃ¶ldrajzi mintÃ¡k,
    
- a rÃ©gi fizetÃ©si mÃ³dok visszaszorulÃ¡sa.
    

A modell pontossÃ¡ga csÃ¶kken, a chargeback-ek nÅ‘nek.

TeendÅ‘k:

- A drift okÃ¡nak elemzÃ©se (feature + koncept drift)
    
- A modell ÃºjratanÃ­tÃ¡sa friss adatokkal
    
- A tanÃºsÃ­tÃ¡si tesztek frissÃ­tÃ©se
    
- A kÃ¼szÃ¶bÃ¶k Ã©s guardrailok mÃ³dosÃ­tÃ¡sa
    

---

## ğŸ§  Review Questions / EllenÅ‘rzÅ‘ kÃ©rdÃ©sek

1. What is the difference between **drift** and **anomaly** in AI systems?
    
2. Why is drift both a data science and a security/safety concern?
    
3. Which layers (input, model, behavior) should be monitored for drift and anomalies?
    
4. How can embedding-based monitoring help with drift detection in NLP or vision models?
    
5. How do drift alerts integrate with [[incident_response_for_ai|Incident Response]] and [[ai_risk_assessment_methodology|Risk Management]]?
    

---

> â€œAI doesnâ€™t usually fail with a bang.  
> It fails with a quiet slide into irrelevance â€” unless you watch it.â€ ğŸ“‰