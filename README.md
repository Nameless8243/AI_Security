<div align="center">

# ğŸ§  AI Security Research Vault  
### by [Tibor KalmÃ¡r](https://www.linkedin.com/in/tibor-kalmar)  
Cybersecurity Engineer â†’ AI Security Architect

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?logo=linkedin)](https://www.linkedin.com/in/tibor-kalmar)
[![GitHub](https://img.shields.io/badge/GitHub-Nameless8243-black?logo=github)](https://github.com/Nameless8243)
[![Obsidian](https://img.shields.io/badge/Built%20with-Obsidian-purple?logo=obsidian)](https://obsidian.md)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

</div>

---

> ğŸ§© A structured, bilingual AI Security learning system â€”  
> built to connect **AI Safety, Risk Management, and Cybersecurity** into one coherent framework.

---

## âš™ï¸ Powered By

- ğŸ§± **Obsidian 1.9+** for structure and MathJax rendering  
- ğŸ¤– **ChatGPT (GPT-5)** for assisted content generation  
- ğŸ§© **Markdown + MathJax** for explainable documentation  
- ğŸ” **Security Frameworks:** NIST AI RMF, ISO 42001, OWASP ML Top-10, MITRE ATLAS  

---

## ğŸŒ Overview

This repository is a **personal AI Security learning framework**, designed to integrate topics like  
**AI Safety, Model Risk, Adversarial ML, Governance, PKI, and Cloud Security**  
into a single, structured, and explainable system.

Itâ€™s built as a **research-grade learning environment** â€” not a simple note collection,  
but a living vault that evolves as I study and experiment.

---

## ğŸ’¡ Purpose

- ğŸ“š To **learn AI Security deeply and systematically** (from trust foundations to GenAI threats)  
- ğŸ¤– To **connect Cloud Security, PKI, and AI Risk Management** into a unified perspective  
- ğŸ§© To **create bilingual educational material** â€” English for clarity, Hungarian for reflection  
- âš™ï¸ To experiment with **AI-assisted automation**, Obsidian workflows, and self-improving vaults  

---

## ğŸ§­ Structure

```text
00_Foundations/                       â†’ Core AI Security concepts, trust, lifecycle, learning path
01_Attack_Taxonomy_and_Threats/       â†’ Threat surfaces, MITRE ATLASâ€“style taxonomy, attack classes
02_Defenses_and_Mitigations/          â†’ Preventive controls, hardening, robustness, privacy defenses
03_Attack_Detection_and_Response/     â†’ Monitoring, anomaly detection, incident handling for AI systems
04_Secure_Deployment_and_Governance/  â†’ Model release, signing, audit logging, compliance & governance
05_AI_Risk_Management_and_Assurance/  â†’ NIST AI RMF, ISO 42001, risk registers, assurance & controls
06_AI_Safety_and_Ethical_Assurance/   â†’ Fairness, explainability, human-in-the-loop, accountability
07_AI_Security_Automation_and_Metrics/â†’ Security-as-Code, Policy-as-Code, telemetry, KPIs, automation
08_Generative_AI_Security/            â†’ RAG security, prompt injection, watermarking, GenAI supply chain
99_Glossary/                          â†’ Cross-linked core concepts (EN/HU glossary)
```

Each section is bilingual (ğŸ‡¬ğŸ‡§ English + ğŸ‡­ğŸ‡º Hungarian) and formatted for  
**Obsidian 1.9+ MathJax** â€” including formulas, lineage links, and visual cues.

---

## ğŸ”— Standards and Frameworks

This Vault aligns with:

- **NIST AI RMF 1.0**
    
- **ISO/IEC 42001:2023**
    
- **EU AI Act â€“ Risk-based Governance**
    
- **MITRE ATLAS & OWASP ML Top 10**
    
- **Zero-Trust for AI Systems**
    

---

## âš–ï¸ Ethics & Compliance

This project contains **only educational and research content**.  
No proprietary, confidential, or organization-specific data is included.  
All examples and architectures are **theoretical** or **publicly documented** sources.

---

## ğŸ“ˆ Learning Roadmap

> Iâ€™m currently transitioning from PKI & Cloud Security engineering  
> to a full AI Security & Governance specialization.

Planned progression:

1. ğŸ§© Complete theory (AI Security Vault â€” current stage)
    
2. âš™ï¸ Build lab environments (adversarial testing, model validation, RAG pipelines) 
    
3. ğŸ§  Apply for AI Security Engineer / Architect roles
    
4. ğŸ§¾ Contribute to open-source frameworks and research
    

---

## ğŸš€ Next Steps

-  Add practical labs (adversarial attack demos, prompt injection tests)
    
-  Expand Automation & Metrics with CI/CD guardrails
    
-  Publish bilingual mini-guides for explainability & fairness
    

---

## ğŸ License

Released under the **MIT License** â€” see [LICENSE](LICENSE) for details.

**Copyright (c) 2025 Tibor KalmÃ¡r**

> _Supplemental Notice (AI-Assisted Content Disclaimer)_  
> This repository was developed and written with the assistance of large language models (LLMs).  
> While the author has reviewed and edited the material, it may contain factual,  
> technical, or linguistic inaccuracies.  
> All content is provided for educational and research purposes only and  
> should not be considered professional or authoritative advice.  
> Users are encouraged to independently verify information before applying it in production.

---

## âœ¨ Author

**Tibor KalmÃ¡r** â€” Cybersecurity Engineer (PKI & Cloud Security)  
ğŸ” Transitioning into **AI Security Architecture**  
ğŸŒ GitHub: Nameless8243  
ğŸ’¼ LinkedIn: Tibor KalmÃ¡r
