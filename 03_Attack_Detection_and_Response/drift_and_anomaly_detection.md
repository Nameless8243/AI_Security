---
version: "3.2"
section_type: "detection"
agent: "Learning Mentor"
---
# ğŸŒŠ Drift and Anomaly Detection / Drift- Ã©s anomÃ¡lia-detektÃ¡lÃ¡s

---

## ğŸŒ Concept Overview / Fogalmi Ã¡ttekintÃ©s

**EN:**  
Drift and anomaly detection are essential to preserve **trust, accuracy, and resilience** in deployed AI systems. Over time, the environment, data sources, and user behavior evolve â€” meaning the modelâ€™s original assumptions slowly become invalid. This phenomenon is known as **model drift**, and if left unchecked, it can silently corrupt predictions and introduce hidden vulnerabilities.  

**HU:**  
A drift- Ã©s anomÃ¡lia-detektÃ¡lÃ¡s alapvetÅ‘ szerepet jÃ¡tszik a **megbÃ­zhatÃ³sÃ¡g, pontossÃ¡g Ã©s robusztussÃ¡g** fenntartÃ¡sÃ¡ban. Az idÅ‘ mÃºlÃ¡sÃ¡val a kÃ¶rnyezet, az adatforrÃ¡sok Ã©s a felhasznÃ¡lÃ³i viselkedÃ©s is vÃ¡ltozik â€” Ã­gy a modell eredeti feltÃ©telezÃ©sei fokozatosan Ã©rvÃ©nyÃ¼ket vesztik. Ezt a jelensÃ©get nevezzÃ¼k **modell-driftnek**, Ã©s ha nem figyeljÃ¼k, csendben torzÃ­thatja az elÅ‘rejelzÃ©seket, biztonsÃ¡gi rÃ©seket okozva.

---

## ğŸ’¡ Core Idea / Alapelv

**EN:**  
Every model is trained under a specific statistical view of the world. When the real data distribution \(P_{real}(x)\) starts to deviate from the training distribution \(P_{train}(x)\), we experience drift. The earlier we detect this, the less risk we face â€” whether itâ€™s financial mispredictions or adversarial model manipulation.  

**HU:**  
Minden modell egy adott statisztikai vilÃ¡gkÃ©pre Ã©pÃ¼l. Amikor a valÃ³s adateloszlÃ¡s \(P_{real}(x)\) eltÃ©r a tanÃ­tÃ³ eloszlÃ¡stÃ³l \(P_{train}(x)\), drift jelensÃ©g lÃ©p fel. MinÃ©l korÃ¡bban Ã©szleljÃ¼k ezt, annÃ¡l kisebb a kockÃ¡zat â€” legyen szÃ³ pÃ©nzÃ¼gyi tÃ©vedÃ©sekrÅ‘l vagy adverszÃ¡riÃ¡lis manipulÃ¡ciÃ³rÃ³l.

---

## ğŸ§® Mathematical View / Matematikai szemlÃ©let

**EN:**  
We quantify drift by measuring the statistical distance between the training and current input distributions:
$$
D_drift = d(P_train(x), P_real(x))
$$
If this distance exceeds a threshold Ï„, the system flags a potential concept drift:
$$
D_drift > Ï„ â‡’ alert("drift")
$$
Typical distance measures include KL-divergence, Jensenâ€“Shannon distance, and the Population Stability Index (PSI).

**HU:**  
A drift mÃ©rtÃ©ke a tanÃ­tÃ³ Ã©s az aktuÃ¡lis adateloszlÃ¡s kÃ¶zÃ¶tti statisztikai tÃ¡volsÃ¡g:
$$
D_drift = d(P_train(x), P_real(x))
$$
Ha ez a tÃ¡volsÃ¡g meghaladja a kÃ¼szÃ¶bÃ¶t Ï„, a rendszer koncepciÃ³driftet jelez:
$$
D_drift > Ï„ â‡’ alert("drift")
$$
A leggyakoribb tÃ¡volsÃ¡gmÃ©rÅ‘k: KL-divergencia, Jensenâ€“Shannon-tÃ¡volsÃ¡g Ã©s a populÃ¡ciÃ³stabilitÃ¡si index (PSI).

---

## ğŸ§© Types of Drift / Drift tÃ­pusai

**EN:**  
- **Data drift:** Input features change in distribution or meaning.  
- **Concept drift:** The relationship between inputs and outputs evolves.  
- **Model drift:** The internal state or learned embeddings shift after updates or retraining.  

**HU:**  
- **Adatdrift:** A bemeneti jellemzÅ‘k eloszlÃ¡sa vagy jelentÃ©se mÃ³dosul.  
- **KoncepciÃ³drift:** MegvÃ¡ltozik az inputâ€“output kapcsolat logikÃ¡ja.  
- **Modelldrift:** A modell belsÅ‘ paramÃ©terei vagy embeddingjei eltolÃ³dnak frissÃ­tÃ©s vagy ÃºjratanÃ­tÃ¡s hatÃ¡sÃ¡ra.

---

## âš™ï¸ Anomaly Detection in AI / AnomÃ¡liÃ¡k detektÃ¡lÃ¡sa az AI-ban

**EN:**  
Anomaly detection focuses on identifying *rare or abnormal* inputs, patterns, or predictions that deviate from expected behavior. In AI security, anomalies can indicate:
- [[adversarial_input_detection|Adversarial Inputs]] attempting to fool the model  
- [[data_poisoning|Data Poisoning]] during training  
- Sensor malfunctions or corrupted data feeds  
- Model degradation or unauthorized fine-tuning  

**HU:**  
Az anomÃ¡lia-detektÃ¡lÃ¡s cÃ©lja a *ritka vagy szokatlan* bemenetek, mintÃ¡k Ã©s kimenetek azonosÃ­tÃ¡sa, amelyek eltÃ©rnek a vÃ¡rt viselkedÃ©stÅ‘l. AI-biztonsÃ¡gban az anomÃ¡liÃ¡k utalhatnak:
- a modell megtÃ©vesztÃ©sÃ©re irÃ¡nyulÃ³ [[adversarial_input_detection|Adversarial Inputs]] prÃ³bÃ¡lkozÃ¡sokra,  
- tanÃ­tÃ¡si szakaszban tÃ¶rtÃ©nÅ‘ [[data_poisoning|Data Poisoning]] tÃ¡madÃ¡sokra,  
- szenzorhibÃ¡kra vagy sÃ©rÃ¼lt adatfolyamokra,  
- modellromlÃ¡sra vagy illetÃ©ktelen finomhangolÃ¡sra.

---

## ğŸ§  Example Scenario / PÃ©ldahelyzet

**EN:**  
A self-driving car model trained in summer conditions encounters snow for the first time. Feature distributions like brightness, edge density, and object contours shift drastically. Drift detection flags this, triggering a retraining pipeline before the modelâ€™s perception errors become dangerous.  

**HU:**  
Egy Ã¶nvezetÅ‘ autÃ³ modellje nyÃ¡ri kÃ¶rÃ¼lmÃ©nyek kÃ¶zÃ¶tt tanul, majd elÅ‘szÃ¶r talÃ¡lkozik hÃ³val. Az olyan jellemzÅ‘k, mint a fÃ©nyerÅ‘, az Ã©lsÅ±rÅ±sÃ©g Ã©s az objektumkontÃºrok eloszlÃ¡sa drasztikusan megvÃ¡ltozik. A drift-detektÃ¡lÃ¡s jelzi a vÃ¡ltozÃ¡st, Ã©s ÃºjratanÃ­tÃ¡si folyamatot indÃ­t, mielÅ‘tt a modell hibÃ¡s Ã©s veszÃ©lyes dÃ¶ntÃ©seket hozna.

---

## ğŸ§­ Integration with Lifecycle / IntegrÃ¡ciÃ³ az Ã©letciklusba

**EN:**  
Drift and anomaly monitoring are integral parts of [[model_monitoring|Model Monitoring]] and [[ai_governance|AI Governance]]. When coupled with automated retraining, explainability checks, and [[data_versioning|Data Versioning]], they maintain a continuous loop of alignment between model behavior and real-world data.  

**HU:**  
A drift- Ã©s anomÃ¡liamonitoring szorosan kapcsolÃ³dik a [[model_monitoring|Model Monitoring]] Ã©s az [[ai_governance|AI Governance]] folyamatokhoz. Ha automatizÃ¡lt ÃºjratanÃ­tÃ¡ssal, magyarÃ¡zhatÃ³sÃ¡gi vizsgÃ¡latokkal Ã©s [[data_versioning|Data Versioning]] rendszerrel kombinÃ¡ljuk, akkor a modell mÅ±kÃ¶dÃ©se folyamatosan igazodik a valÃ³s adatokhoz Ã©s kÃ¶rnyezethez.

---

## ğŸ§­ Review Questions / EllenÅ‘rzÅ‘ kÃ©rdÃ©sek

1. What causes model drift and how does it impact security?  
2. How can statistical distance help detect drift?  
3. What is the difference between data drift and concept drift?  
4. Why is anomaly detection critical for trustworthy AI systems?  
5. How does drift monitoring connect to AI governance and retraining cycles?

---

> â€œAdaptation without awareness is chaos â€” detection turns it into learning.â€ ğŸ’¡
