---
id: supply_chain_attack
title: "Supply Chain Attack / EllÃ¡tÃ¡si lÃ¡nc tÃ¡madÃ¡s"
lang: ["hu", "en"]
version: "3.1"
vault: "AI Security Research Vault 2.0"
section_type: "01_Glossary"
agent: "Threat Mapper"
tags:
  - ai_security
  - glossary
  - underscore_slug
---
# Supply Chain Attacks in AI

_When your model inherits someone elseâ€™s compromise_

---

## ğŸŒ Introduction

**EN:**  
Every AI system depends on an ecosystem â€” datasets, pretrained models, third-party libraries, frameworks, APIs, and deployment environments.  
A **Supply Chain Attack** in AI targets this ecosystem rather than the model itself. The attacker compromises one component (like a dataset repository, dependency, or model hub), and that compromise silently spreads downstream to every system that consumes it.

In traditional IT, supply chain attacks target software dependencies. In AI, they target _knowledge dependencies_.

**HU:**  
Minden mestersÃ©ges intelligencia rendszer egy Ã¶koszisztÃ©mÃ¡ra Ã©pÃ¼l â€” adatkÃ©szletekre, elÅ‘re betanÃ­tott modellekre, kÃ¼lsÅ‘ kÃ¶nyvtÃ¡rakra, API-kra Ã©s futtatÃ¡si kÃ¶rnyezetekre.  
Az **AI ellÃ¡tÃ¡si lÃ¡nc elleni tÃ¡madÃ¡s (Supply Chain Attack)** nem magÃ¡t a modellt, hanem ezt az Ã¶koszisztÃ©mÃ¡t cÃ©lozza. A tÃ¡madÃ³ egyetlen elemet kompromittÃ¡l (pÃ©ldÃ¡ul adatforrÃ¡st, fÃ¼ggÅ‘sÃ©get vagy modellelÅ‘zmÃ©nyt), Ã©s a fertÅ‘zÃ©s csendben tovÃ¡bbterjed minden rendszerre, amely ezt az elemet felhasznÃ¡lja.

A hagyomÃ¡nyos IT-ban az ellÃ¡tÃ¡si lÃ¡nc tÃ¡madÃ¡s a szoftver-fÃ¼ggÅ‘sÃ©geket cÃ©lozza â€” az AI-ban viszont _a tudÃ¡s-fÃ¼ggÅ‘sÃ©geket_.

---

## ğŸ§  The Nature of AI Supply Chains

**EN:**  
Unlike classical software, AI systems are built from â€œlivingâ€ components: data that constantly evolves, open-source checkpoints, and shared pretrained weights.  
A modern AI product may rely on:

- **Datasets** scraped from public sources,
    
- **Pretrained models** downloaded from hubs like Hugging Face,
    
- **Libraries** that include optimized but opaque CUDA kernels,
    
- **Third-party inference APIs**, and
    
- **Container images** maintained by different vendors.
    

Each link introduces potential infiltration points. A poisoned dataset, compromised dependency, or tampered model weight can all serve as Trojan vectors.

**HU:**  
A klasszikus szoftverekkel ellentÃ©tben az AI rendszerek â€Ã©lÅ‘â€ elemekbÅ‘l Ã©pÃ¼lnek: folyamatosan vÃ¡ltozÃ³ adatokbÃ³l, nyÃ­lt forrÃ¡sÃº checkpointokbÃ³l Ã©s megosztott, elÅ‘tanÃ­tott sÃºlyokbÃ³l.  
Egy modern AI termÃ©k tÃ¡maszkodhat pÃ©ldÃ¡ul:

- **NyilvÃ¡nos forrÃ¡sbÃ³l gyÅ±jtÃ¶tt adatkÃ©szletekre**,
    
- **Hugging Face-szerÅ± hubokrÃ³l letÃ¶ltÃ¶tt modellekre**,
    
- **KÃ¼lsÅ‘ kÃ¶nyvtÃ¡rakra**, amelyek optimalizÃ¡lt, de Ã¡tlÃ¡thatatlan CUDA kÃ³dot tartalmaznak,
    
- **Harmadik fÃ©l inferencia-API-kra**,
    
- **KontÃ©ner-image-ekre**, amelyeket kÃ¼lÃ¶n gyÃ¡rtÃ³k tartanak karban.
    

Mindegyik lÃ¡ncszem potenciÃ¡lis bejutÃ¡si pontot jelent. Egy mÃ©rgezett adatkÃ©szlet, kompromittÃ¡lt fÃ¼ggÅ‘sÃ©g vagy manipulÃ¡lt modellsÃºly mind trÃ³jai vektorkÃ©nt mÅ±kÃ¶dhet.

---

## âš™ï¸ Common Attack Pathways

**EN:**  
AI supply chain compromise can occur at several stages of the [[ai_lifecycle|AI Lifecycle]]:

1. **Data ingestion:** poisoned datasets or mislabeled corpora introduce bias or backdoors. (â†’ [[data_poisoning|Data Poisoning]])
    
2. **Model acquisition:** downloading pretrained checkpoints that contain hidden triggers or malicious code in serialized objects.
    
3. **Dependency compromise:** inserting backdoored code into PyPI or NPM packages used for model training or serving.
    
4. **Model hosting & APIs:** replacing legitimate hosted models or weights with altered ones.
    
5. **CI/CD pipelines:** poisoning build containers, introducing rogue dependencies during automated retraining.
    

These vectors blur the boundary between _attack_ and _maintenance_: what seems like an update can be an intrusion.

**HU:**  
Az AI ellÃ¡tÃ¡si lÃ¡nc kompromittÃ¡lÃ¡sa az [[ai_lifecycle|AI Ã©letciklus]] tÃ¶bb szakaszÃ¡ban is megtÃ¶rtÃ©nhet:

1. **AdatgyÅ±jtÃ©s:** mÃ©rgezett adatkÃ©szletek vagy hibÃ¡s cÃ­mkÃ©zÃ©s torzÃ­tÃ¡st, backdoort hoz be (â†’ [[data_poisoning|Data Poisoning]]).
    
2. **Model-beszerzÃ©s:** elÅ‘tanÃ­tott checkpointok letÃ¶ltÃ©se, amelyek rejtett triggereket vagy kÃ¡rtÃ©kony kÃ³dot tartalmaznak.
    
3. **FÃ¼ggÅ‘sÃ©gek kompromittÃ¡lÃ¡sa:** backdoor-kÃ³d beszÃºrÃ¡sa a PyPI- vagy NPM-csomagokba, amelyeket a tanÃ­tÃ¡s vagy futtatÃ¡s sorÃ¡n hasznÃ¡lnak.
    
4. **Model-hosztolÃ¡s Ã©s API-k:** a hivatalos modellek vagy sÃºlyok manipulÃ¡lt vÃ¡ltozatokkal valÃ³ helyettesÃ­tÃ©se.
    
5. **CI/CD pipeline-ok:** build-kontÃ©nerek mÃ©rgezÃ©se, rosszindulatÃº fÃ¼ggÅ‘sÃ©gek beÃ©pÃ­tÃ©se az automatizÃ¡lt ÃºjratanÃ­tÃ¡s sorÃ¡n.
    

Ezek a vektorok elmosÃ³dott hatÃ¡rt hÃºznak a _karbantartÃ¡s_ Ã©s a _tÃ¡madÃ¡s_ kÃ¶zÃ¶tt: ami frissÃ­tÃ©snek tÅ±nik, az valÃ³jÃ¡ban behatolÃ¡s lehet.

---

## ğŸ§© Notable Real-World Incidents

**EN:**

- **Python supply chain attacks (2022-2023):** malicious PyPI packages with similar names (â€œtorch-tritonâ€, â€œreqeustsâ€) stole credentials from training pipelines.
    
- **Model Hub Poisoning:** in 2023, researchers demonstrated backdoored vision transformers uploaded to model repositories that infected downstream users during inference.
    
- **Dataset poisoning:** open-source image datasets were found to contain hidden triggers embedded in metadata EXIF tags.
    
- **Container compromise:** prebuilt Docker images used for GPU training included unauthorized network callbacks.
    

Each case shows how _trust is transitive_ â€” and one unverified source can taint an entire ML ecosystem.

**HU:**

- **Python ellÃ¡tÃ¡si lÃ¡nc tÃ¡madÃ¡sok (2022â€“2023):** rosszindulatÃº PyPI-csomagok (â€torch-tritonâ€, â€reqeustsâ€) hitelesÃ­tÅ‘ adatokat loptak a tanÃ­tÃ¡si pipeline-okbÃ³l.
    
- **Model Hub mÃ©rgezÃ©s:** 2023-ban kutatÃ³k backdoor-os vision transformer modelleket tÃ¶ltÃ¶ttek fel, amelyek a letÃ¶ltÅ‘ rendszereket fertÅ‘ztÃ©k.
    
- **AdatkÃ©szlet-mÃ©rgezÃ©s:** nyÃ­lt kÃ©padatbÃ¡zisokban rejtett triggerek voltak az EXIF-metadatÃ¡ban.
    
- **KontÃ©ner-kompromittÃ¡lÃ¡s:** elÅ‘re gyÃ¡rtott GPU-trÃ©ning image-ek illetÃ©ktelen hÃ¡lÃ³zati callbackeket tartalmaztak.
    

Ezek az esetek megmutatjÃ¡k, hogy a _bizalom transzitÃ­v_: egyetlen nem ellenÅ‘rzÃ¶tt forrÃ¡s is beszennyezheti az egÃ©sz ML Ã¶koszisztÃ©mÃ¡t.

---

## ğŸ›¡ï¸ Defense Strategies

**EN:**  
Building resilience against supply chain attacks requires shifting from _trust-by-default_ to **[[zero_trust_for_ai|Zero Trust for AI]]**. Key practices include:

- **AI SBOM / MBOM:** maintain Software and Model Bill of Materials listing every dependency, dataset, and weight file (â†’ [[ai_sbom_and_mbom_management|AI SBOM]]).
    
- **Cryptographic signing:** verify the integrity of datasets, containers, and pretrained weights.
    
- **Reproducible pipelines:** automate builds using immutable base images and version-locked dependencies.
    
- **Data provenance checks:** confirm dataset origin and authenticity.
    
- **Threat intelligence feeds:** subscribe to alerts for compromised model hubs or package registries.
    
- **Continuous validation:** automatically test and hash-compare models after every retraining or update.
    

**HU:**  
Az ellÃ¡tÃ¡si lÃ¡nc tÃ¡madÃ¡sok elleni vÃ©dekezÃ©shez a _bizalom alapÃ©rtelmezett_ megkÃ¶zelÃ­tÃ©srÅ‘l Ã¡t kell Ã¡llni a **[[zero_trust_for_ai|Zero Trust AI]]** szemlÃ©letre. FÅ‘ gyakorlatok:

- **AI SBOM / MBOM:** minden fÃ¼ggÅ‘sÃ©g, dataset Ã©s modellsÃºly nyilvÃ¡ntartÃ¡sa (â†’ [[ai_sbom_and_mbom_management|AI SBOM]]).
    
- **KriptogrÃ¡fiai alÃ¡Ã­rÃ¡s:** az adatkÃ©szletek, kontÃ©nerek Ã©s sÃºlyfÃ¡jlok integritÃ¡s-ellenÅ‘rzÃ©se.
    
- **ReprodukÃ¡lhatÃ³ pipeline-ok:** vÃ¡ltoztathatatlan base image-ek Ã©s verziÃ³-rÃ¶gzÃ­tett fÃ¼ggÅ‘sÃ©gek hasznÃ¡lata.
    
- **Adateredet-ellenÅ‘rzÃ©s:** az adatforrÃ¡sok Ã©s hitelessÃ©g validÃ¡lÃ¡sa.
    
- **Threat intelligence:** Ã©rtesÃ­tÃ©sek a fertÅ‘zÃ¶tt modell- vagy csomag-forrÃ¡sokrÃ³l.
    
- **Folyamatos validÃ¡lÃ¡s:** minden retrÃ©ning vagy frissÃ­tÃ©s utÃ¡n automatikus tesztelÃ©s Ã©s hash-Ã¶sszevetÃ©s.
    

---

## âš–ï¸ Governance & Compliance Angle

**EN:**  
AI supply chain risk is now embedded in frameworks like [[ai_supply_chain_framework_comparison|NIST AI RMF]], [[ai_risk_assessment_methodology|ISO/IEC 23894]], and the EU AI Act.  
Organizations must demonstrate traceability â€” knowing exactly which data and model components were used, when, and by whom.

**HU:**  
Az AI ellÃ¡tÃ¡si lÃ¡nc kockÃ¡zata ma mÃ¡r beÃ©pÃ¼lt a [[ai_supply_chain_framework_comparison|NIST AI RMF]], [[ai_risk_assessment_methodology|ISO/IEC 23894]] Ã©s az EU AI Act szabÃ¡lyozÃ¡saiba.  
A szervezeteknek bizonyÃ­taniuk kell a nyomon kÃ¶vethetÅ‘sÃ©get â€” pontosan tudniuk kell, mely adatokat Ã©s modullelemeket, mikor Ã©s ki hasznÃ¡lt.

---

## ğŸ” Review Questions / EllenÅ‘rzÅ‘ kÃ©rdÃ©sek

1. How do AI supply chain attacks differ from traditional software supply chain attacks?
    
2. At which stages of the AI lifecycle can poisoning or compromise occur?
    
3. Why is Zero Trust a key architectural principle for AI supply chains?
    
4. What are the benefits of maintaining a complete AI SBOM?
    
5. How can regulatory frameworks influence supply chain hygiene?
    

---

> _â€œEvery dependency is a doorway â€” and in AI, doors multiply faster than you can count.â€_