---
id: data_exfiltration
title: "Data Exfiltration / AdatszivÃ¡rgÃ¡s"
lang: ["hu", "en"]
version: "3.1"
vault: "AI Security Research Vault 2.0"
section_type: "01_Glossary"
agent: "Threat Mapper"
tags:
  - ai_security
  - glossary
  - underscore_slug
---
# Data Exfiltration

_How models â€” unintentionally or maliciously â€” leak sensitive information_

---

## ğŸŒ Introduction

**EN:**  
Data exfiltration in the AI context is the process by which sensitive information leaves a protected boundary via an AI system. This can happen intentionally (a compromised component sending secrets out) or unintentionally (a model that memorized and later reveals private training data). Modern systems â€” with APIs, logs, and user-facing completions â€” provide many channels for leakage. Understanding exfiltration means treating the model and its surrounding infra as potential _data egress vectors_, not just compute artifacts.

**HU:**  
Az adatkiszivÃ¡rgÃ¡s (data exfiltration) AI-kÃ¶rnyezetben azt jelenti, hogy Ã©rzÃ©keny informÃ¡ciÃ³ kerÃ¼l ki egy vÃ©dett hatÃ¡ron keresztÃ¼l az AI rendszer rÃ©vÃ©n. Ez tÃ¶rtÃ©nhet szÃ¡ndÃ©kosan (kompromittÃ¡lt komponens szivÃ¡rogtat) vagy vÃ©letlenÃ¼l (a modell memorizÃ¡lt adatokat ad vissza). A mai rendszerek â€” API-k, logok, felhasznÃ¡lÃ³i vÃ¡laszok â€” sok csatornÃ¡t kÃ­nÃ¡lnak a szivÃ¡rgÃ¡sra. Az exfiltrÃ¡ciÃ³ megÃ©rtÃ©se azt jelenti, hogy a modellt Ã©s a kÃ¶rnyezetÃ©t potenciÃ¡lis _kimeneti csatornÃ¡kkÃ©nt_ kell kezelni, nem csak szÃ¡mÃ­tÃ¡si egysÃ©gekkÃ©nt.

---

## ğŸ§  Why AI Changes the Exfiltration Game

**EN:**  
AI systems blend storage, computation, and communication. Unlike traditional databases where leaks are obvious (files copied, DB dumps), models can _encode_ information in subtle ways â€” logits, completions, embeddings, or even timing differences. Moreover, attackers can manipulate inputs (prompt engineering, steganographic payloads) to coax models into producing sensitive content. The attackerâ€™s toolbox includes both direct probes (query-response) and covert techniques (covert channels embedded in outputs).

**HU:**  
Az AI rendszerek tÃ¡rolÃ¡st, szÃ¡mÃ­tÃ¡st Ã©s kommunikÃ¡ciÃ³t Ã¶tvÃ¶znek. EllentÃ©tben a hagyomÃ¡nyos adatbÃ¡zisokkal, ahol a kiszivÃ¡rgÃ¡s egyÃ©rtelmÅ± (fÃ¡jlok mÃ¡solÃ¡sa, dump-ok), a modellek az informÃ¡ciÃ³t finom mÃ³don _kÃ³dolhatjÃ¡k_ â€” logitek, kiegÃ©szÃ­tÃ©sek, embeddingek vagy akÃ¡r idÅ‘zÃ­tÃ©si kÃ¼lÃ¶nbsÃ©gek formÃ¡jÃ¡ban. RÃ¡adÃ¡sul a tÃ¡madÃ³k az inputok manipulÃ¡lÃ¡sÃ¡val (prompt-engineering, steganogrÃ¡fiai payloadok) is kicsalhatjÃ¡k az Ã©rzÃ©keny tartalmat. A tÃ¡madÃ³k eszkÃ¶ztÃ¡ra kÃ¶zvetlen prÃ³bÃ¡kat (lekÃ©rdezÃ©s-vÃ¡lasz) Ã©s covert csatornÃ¡kat egyarÃ¡nt tartalmaz.

---

## âš™ï¸ Main Exfiltration Channels

**EN:**

1. **Output Retrieval (Direct):** the model outputs memorized data verbatim (e.g., PII, API keys) when given certain prompts â€” overlaps with [[model_inversion|Model Inversion]] and [[membership_inference_attacks|Membership Inference]].
    
2. **Steganographic Outputs:** attackers design prompts that cause the model to embed data in innocuous-looking text or images (e.g., hidden base64 within prose).
    
3. **Embedding Leakage:** vector databases return embeddings or similarity scores that can be probed to reconstruct original documents or reveal membership.
    
4. **Side Channels:** timing, error messages, or resource-usage patterns reveal internal state or data about training/serving artifacts.
    
5. **Compromised Pipelines:** CI/CD, model registries, or dataset stores that are exfiltrated by malicious insiders or supply-chain compromises.
    

Each channel requires different defensive approaches â€” from output filtering to provenance and runtime isolation.

**HU:**

1. **Kimenet-alapÃº kinyerÃ©s (kÃ¶zvetlen):** a modell pontosan visszaadja a memorizÃ¡lt adatot (pl. szemÃ©lyes adatok, API-kulcsok) bizonyos promptokra â€” ez Ã¡tfedÃ©s a [[model_inversion|modell-inverziÃ³]] Ã©s a [[membership_inference_attacks|tagsÃ¡gi tÃ¡madÃ¡sok]] terÃ¼letÃ©vel.
    
2. **SzteganogrÃ¡fiai kimenetek:** a tÃ¡madÃ³k olyan promptokat terveznek, amelyek a modellt Ã¡rtalmatlan szÃ¶vegbe vagy kÃ©pekbe rejtett adatok beÃ¡gyazÃ¡sÃ¡ra kÃ©sztetik (pl. base64 kÃ³dok prÃ³zÃ¡ban).
    
3. **Embedding-szivÃ¡rgÃ¡s:** a vektoradatbÃ¡zisokbÃ³l visszakapott embeddingek vagy similarity score-ok vizsgÃ¡latÃ¡val visszaÃ¡llÃ­thatÃ³k eredeti dokumentumdarabok vagy felfedhetÅ‘ a tagsÃ¡g.
    
4. **OldalcsatornÃ¡k:** idÅ‘zÃ­tÃ©s, hibajelzÃ©sek vagy erÅ‘forrÃ¡s-hasznÃ¡lati mintÃ¡zatok fedhetnek fel belsÅ‘ Ã¡llapotokat vagy adatinformÃ¡ciÃ³t.
    
5. **KompromittÃ¡lt pipeline-ok:** CI/CD, modellregiszterek vagy adattÃ¡rolÃ³k, amelyeket rosszindulatÃº belsÅ‘ szereplÅ‘k vagy ellÃ¡tÃ¡si lÃ¡nc tÃ¡madÃ¡sok hasznÃ¡lnak exfiltrÃ¡ciÃ³ra.
    

Minden csatornÃ¡hoz mÃ¡s-mÃ¡s vÃ©dekezÃ©si stratÃ©giÃ¡k szÃ¼ksÃ©gesek â€” a kimenetszÅ±rÃ©stÅ‘l a provenance-ig Ã©s a futtatÃ¡si izolÃ¡ciÃ³ig.

---

## ğŸ§© Concrete Attack Patterns

**EN:**

- **Prompt-based retrieval:** craft a prompt that includes a guessed prefix of a secret; model completes the secret.
    
- **Split-query reconstruction:** submit overlapping prompts and stitch completions to recover longer secrets.
    
- **Embedding inversion:** use many queries to a vector store to approximate and reconstruct source text from embeddings.
    
- **Covert channel via formatting:** request outputs with specific whitespace/formatting patterns that encode bits of a secret.
    
- **Insider exfiltration:** a developer with access to model registries or training data exfiltrates artifacts via private endpoints.
    

These patterns may combine: a prompt-engineered probe can use embeddings and then text prompts to refine and reconstruct data.

**HU:**

- **Prompt-alapÃº kinyerÃ©s:** olyan promptot kÃ©szÃ­tenek, amely tartalmaz egy feltÃ©telezett titkos elÅ‘tagot; a modell befejezi a titkot.
    
- **FelhasadÃ³-lekÃ©rdezÃ©s (split-query):** Ã¡tfedÅ‘ promptokkal rÃ©szleteket kÃ©rnek le, majd Ã¶sszeillesztik a rÃ©szleteket hosszabb titkok visszaÃ¡llÃ­tÃ¡sÃ¡hoz.
    
- **Embedding-inverziÃ³:** sok lekÃ©rdezÃ©ssel a vektor-adatbÃ¡zisokbÃ³l megkÃ¶zelÃ­tik Ã©s rekonstruÃ¡ljÃ¡k a forrÃ¡sszÃ¶veget az embeddingekbÅ‘l.
    
- **Covert csatorna formÃ¡zÃ¡ssal:** speciÃ¡lis szÃ³kÃ¶zÃ¶lÃ©si/formÃ¡zÃ¡si mintÃ¡kat kÃ©rnek, amelyek bitkÃ©nt kÃ³dolnak informÃ¡ciÃ³t.
    
- **BelsÅ‘ szereplÅ‘ Ã¡ltali kiszivÃ¡rogtatÃ¡s:** olyan fejlesztÅ‘, aki hozzÃ¡fÃ©r a modellig vagy trÃ©ningadatokhoz, privÃ¡t vÃ©gpontokon keresztÃ¼l viszi ki az artefaktokat.
    

Ezek a mintÃ¡k kombinÃ¡lhatÃ³k: a prompt-engineeringes prÃ³ba embeddingeket hasznÃ¡lva finomÃ­thatÃ³ szÃ¶veges lekÃ©rdezÃ©sekkÃ© az adatrekonstrukciÃ³.

---

## ğŸ›¡ï¸ Defensive Strategies

**EN:**  
Defending against exfiltration requires layered controls, policy, and runtime detection:

- **Strict output governance:** redact or filter PII, limit raw logits and full-text completions; return only top-k labels or paraphrased answers. Tie this to [[model_certification_and_testing|certified behavior]] requirements.
    
- **Query monitoring & anomaly detection:** detect probing patterns (repetitive overlap queries, high-entropy outputs) indicative of exfiltration attempts.
    
- **Rate limiting & client authentication:** throttle suspicious clients and require strong identity for high-volume access. Integrate with [[zero_trust_for_ai|Zero Trust for AI]].
    
- **Embedding controls:** avoid returning raw embeddings; use hashed or tokenized similarity services, or perform similarity-only operations server-side without exposing vectors.
    
- **Provenance & SBOM:** track dataset and model lineage so you can quickly identify which artifact could contain leaked material (â†’ [[ai_sbom_and_mbom_management|AI SBOM]]).
    
- **Differential privacy & memorization checks:** train with privacy guarantees and run membership/memorization audits before deployment (refer to [[membership_inference_attacks|Membership Inference]]).
    
- **Runtime isolation & sandboxing:** isolate untrusted user code or third-party adapters to prevent lateral movement.
    
- **Logging & encrypted telemetry:** capture detailed audit trails (while protecting logs themselves) to support forensic analysis.
    

**HU:**  
Az exfiltrÃ¡ciÃ³ elleni vÃ©delem rÃ©tegzett kontrollt, szabÃ¡lyzatot Ã©s futtatÃ¡s kÃ¶zbeni detektÃ¡lÃ¡st igÃ©nyel:

- **SzigorÃº kimenet-irÃ¡nyÃ­tÃ¡s:** szemÃ©lyes adatok redakÃ¡lÃ¡sa, nyers logitek Ã©s teljes szÃ¶veges kimenetek korlÃ¡tozÃ¡sa; csak top-k cÃ­mkÃ©k vagy parafrÃ¡zis visszaadÃ¡sa. Kapcsold ezeket a [[model_certification_and_testing|tanÃºsÃ­tott viselkedÃ©si]] kÃ¶vetelmÃ©nyekhez.
    
- **LekÃ©rdezÃ©s-monitorozÃ¡s Ã©s anomÃ¡lia-Ã©szlelÃ©s:** felismerni a mÃ³dszeres faggatÃ³ mintÃ¡kat (ismÃ©tlÅ‘dÅ‘, Ã¡tfedÅ‘ lekÃ©rdezÃ©sek, magas entrÃ³piÃ¡jÃº kimenetek) mint exfiltrÃ¡ciÃ³s kÃ­sÃ©rletek.
    
- **Rate limiting Ã©s kliens-hitelesÃ­tÃ©s:** gyanÃºs klienslekÃ©rdezÃ©sek lassÃ­tÃ¡sa, nagy forgalom esetÃ©n erÅ‘s identitÃ¡skÃ¶vetelmÃ©ny. IntegrÃ¡ld a [[zero_trust_for_ai|Zero Trust]] elvekkel.
    
- **Embedding-kontrollok:** ne add vissza a nyers embeddingeket; hasznÃ¡lj meghatÃ¡rozott similarity API-kat, amelyek nem szolgÃ¡ltatnak vektort, vagy hash-eld a vektorokat.
    
- **EredetkÃ¶vetÃ©s Ã©s SBOM:** kÃ¶vesd a dataset- Ã©s modell-lÃ¡ncolatot, Ã­gy gyorsan azonosÃ­thatÃ³, melyik artefaktum tartalmazhatott kiszivÃ¡rgott anyagot (â†’ [[ai_sbom_and_mbom_management|AI SBOM]]).
    
- **DifferenciÃ¡lis adatvÃ©delem Ã©s memorizÃ¡ciÃ³-ellenÅ‘rzÃ©s:** privÃ¡t garanciÃ¡val trenÃ­rozni Ã©s tagsÃ¡gi/memorizÃ¡ciÃ³s auditokat futtatni Ã©lesÃ­tÃ©s elÅ‘tt (â†’ [[membership_inference_attacks|TagsÃ¡gi tÃ¡madÃ¡sok]]).
    
- **FuttatÃ¡si izolÃ¡ciÃ³ Ã©s sandbox:** elkÃ¼lÃ¶nÃ­teni a nem megbÃ­zhatÃ³ felhasznÃ¡lÃ³i kÃ³dot vagy harmadik fÃ©ltÅ‘l szÃ¡rmazÃ³ adaptereket a laterÃ¡lis mozgÃ¡s megakadÃ¡lyozÃ¡sÃ¡ra.
    
- **NaplÃ³zÃ¡s Ã©s titkosÃ­tott telemetria:** rÃ©szletes audit-pÃ¡lyÃ¡k rÃ¶gzÃ­tÃ©se (mikÃ¶zben a naplÃ³kat magukat is vÃ©ded) a vizsgÃ¡latok tÃ¡mogatÃ¡sÃ¡ra.
    

---

## ğŸ§© Detection Signals & Incident Response

**EN:**  
Detection indicators include: unusual query patterns (systematic prefix probes), spikes in high-entropy completions, repeated queries that produce overlapping completions, or unexpected outbound traffic from model-serving nodes. Incident response should include: immediate throttling and blocking, forensic snapshot (model & dataset hashes, recent queries), rolling model rollback (if reversible), and regulatory/legal notification if PII is confirmed exfiltrated. Ensure playbooks include steps to preserve chain-of-custody for audits.

**HU:**  
DetektÃ¡lÃ¡si jelek lehetnek: szokatlan lekÃ©rdezÃ©si mintÃ¡k (rendszeres prefix-prÃ³bÃ¡lkozÃ¡sok), magas entrÃ³piÃ¡jÃº kimenetek hirtelen megjelenÃ©se, ismÃ©tlÅ‘dÅ‘ lekÃ©rdezÃ©sek amelyek Ã¡tfedÅ‘ befejezÃ©seket adnak, vagy vÃ¡ratlan kimenÅ‘ forgalom a modell-futtatÃ³ csomÃ³pontokrÃ³l. Az incidensre adott vÃ¡lasz tartalmazza: azonnali korlÃ¡tozÃ¡s/blokkolÃ¡s, forenzikus pillanatfelvÃ©tel (modell- Ã©s adat-hash-ek, a legutÃ³bbi lekÃ©rdezÃ©sek), modell-visszaÃ¡llÃ­tÃ¡s (ha lehetsÃ©ges), Ã©s szabÃ¡lyozÃ³i/jogi Ã©rtesÃ­tÃ©s, ha szemÃ©lykÃ©nt azonosÃ­thatÃ³ adatok szivÃ¡rogtak. A cselekvÃ©si tervekben szerepeljen a chain-of-custody megÅ‘rzÃ©se auditokhoz.

---

## âš–ï¸ Governance & Policy Controls

**EN:**  
Technical controls must be complemented by policy: data classification, least-privilege access to datasets and model artifacts, contractual controls with third-party model providers, and clear rules for redaction and retention. Make exfiltration risk part of model acceptance criteria: if a candidate model or dataset increases measurable exfiltration risk, it must be rejected or mitigated before deployment.

**HU:**  
A technikai kontrollokat politikai intÃ©zkedÃ©sek egÃ©szÃ­tik ki: adat-osztÃ¡lyozÃ¡s, legkisebb jogosultsÃ¡g elve a datasetekhez Ã©s modell-artefaktumokhoz, szerzÅ‘dÃ©ses zÃ¡radÃ©kok harmadik fÃ©l modell-szolgÃ¡ltatÃ³kkal, valamint vilÃ¡gos szabÃ¡lyok a redakciÃ³ra Ã©s megÅ‘rzÃ©sre. Az exfiltrÃ¡ciÃ³s kockÃ¡zat legyen rÃ©sze a modell-elfogadÃ¡si kritÃ©riumoknak: ha egy modell vagy adatkÃ©szlet nÃ¶veli a mÃ©rhetÅ‘ kiszivÃ¡rgÃ¡si kockÃ¡zatot, el kell utasÃ­tani vagy elÅ‘ kell kÃ©szÃ­teni a mitigÃ¡ciÃ³t Ã©lesÃ­tÃ©s elÅ‘tt.

---

## ğŸ”­ Research & Open Challenges

**EN:**  
Open problems include provable detection of covert channels in generative outputs, scalable privacy constraints for vector stores, and robust metrics for quantifying exfiltration risk across multimodal systems. Research into provable â€œmachine forgetting,â€ encrypted inference, and verifiable computation promises new guardrails â€” but operationalizing them at scale remains a challenge.

**HU:**  
Nyitott problÃ©mÃ¡k: provably detektÃ¡lhatÃ³ covert csatornÃ¡k a generatÃ­v kimenetekben, skÃ¡lÃ¡zhatÃ³ adatvÃ©delmi korlÃ¡tok vektoradatbÃ¡zisokra, Ã©s robosztus metrikÃ¡k az exfiltrÃ¡ciÃ³s kockÃ¡zat mÃ©rÃ©sÃ©re multimodÃ¡lis rendszerekben. A â€gÃ©pi felejtÃ©sâ€, titkosÃ­tott inferencia Ã©s verifikÃ¡lhatÃ³ szÃ¡mÃ­tÃ¡s kutatÃ¡sa Ãºj vÃ©dÅ‘sÃ¡vokat Ã­gÃ©r, de ezek Ã©les, nagy lÃ©ptÃ©kÅ± bevezetÃ©se mÃ©g kihÃ­vÃ¡s.

---

## ğŸ” Review Questions / EllenÅ‘rzÅ‘ kÃ©rdÃ©sek

1. Name five distinct channels through which AI systems can exfiltrate data.
    
2. How can embeddings lead to reconstruction of source text?
    
3. What runtime signals are typical for exfiltration attempts?
    
4. Why should model acceptance criteria include exfiltration risk assessment?
    
5. Describe one policy and one technical control that reduce exfiltration risk.
    

---

> _â€œSecrecy in AI is not a perimeter problem only â€” it is a behavior problem. Watch what it says, not just where it sits.â€_