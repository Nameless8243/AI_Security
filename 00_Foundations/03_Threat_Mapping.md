---
id: 03_threat_mapping
title: "03 â€“ Threat Mapping / FenyegetÃ©si tÃ©rkÃ©p"
lang: ["hu", "en"]
version: "3.1"
vault: "AI Security Research Vault 2.0"
section_type: "00_Foundations"
role: "threat_mapper"
tags:
  - ai_security
  - foundations
  - underscore_slugs
---
# Threat Mapping in AI Systems

_Seeing the full attack surface of artificial intelligence_

---

## ğŸŒ Introduction

**EN:**  
Every secure system begins with a map â€” a mental model of where things can go wrong.  
In AI security, that map is called **Threat Mapping**.  
It connects the [[ai_lifecycle|AI Lifecycle]] to real-world attack surfaces and helps defenders anticipate how vulnerabilities evolve as data, models, and infrastructure interact.

Without a threat map, protection becomes guesswork â€” and in AI, where systems learn, adapt, and mutate, guesswork is fatal.

**HU:**  
Minden biztonsÃ¡gos rendszer tÃ©rkÃ©ppel kezdÅ‘dik â€” egy mentÃ¡lis modellel arrÃ³l, hol tÃ¶rtÃ©nhet baj.  
Az AI biztonsÃ¡gban ezt hÃ­vjuk **Threat Mappingnek**, azaz fenyegetÃ©s-tÃ©rkÃ©pezÃ©snek.  
Ez kÃ¶ti Ã¶ssze az [[ai_lifecycle|AI Ã©letciklust]] a valÃ³s tÃ¡madÃ¡si felÃ¼letekkel, Ã©s segÃ­t a vÃ©delmi szakÃ©rtÅ‘knek elÅ‘re lÃ¡tni, hogyan alakulnak a sebezhetÅ‘sÃ©gek, ahogy az adatok, modellek Ã©s infrastruktÃºrÃ¡k kÃ¶lcsÃ¶nhatÃ¡sba lÃ©pnek.

TÃ©rkÃ©p nÃ©lkÃ¼l a vÃ©delem talÃ¡lgatÃ¡s. Az AI-ban, ahol a rendszerek tanulnak, alkalmazkodnak Ã©s vÃ¡ltoznak â€” a talÃ¡lgatÃ¡s vÃ©gzetes.

---

## ğŸ§  The Philosophy of Threat Mapping

**EN:**  
Traditional threat models assume fixed assets and static code.  
AI, however, introduces _dynamic intent_ â€” systems that modify themselves through learning.  
Therefore, AI threat mapping must include both **static surfaces** (e.g., model weights, APIs, datasets) and **adaptive surfaces** (e.g., model behavior drift, [[prompt_injection|prompt injection]] vectors, or evolving supply chains).

Mapping is not documentation â€” itâ€™s _situational awareness_.  
The map should reflect how attackers think: what they see, what they can reach, and what they can manipulate.

**HU:**  
A hagyomÃ¡nyos fenyegetÃ©smodellek rÃ¶gzÃ­tett eszkÃ¶zÃ¶kkel Ã©s statikus kÃ³ddal szÃ¡molnak.  
Az AI azonban bevezeti a _dinamikus szÃ¡ndÃ©kot_ â€” a rendszereket, amelyek tanulÃ¡s ÃºtjÃ¡n mÃ³dosÃ­tjÃ¡k Ã¶nmagukat.  
EzÃ©rt az AI threat mappingnek egyszerre kell lefednie a **statikus felÃ¼leteket** (pl. modellek, API-k, adatkÃ©szletek) Ã©s az **adaptÃ­v felÃ¼leteket** (pl. viselkedÃ©si drift, [[prompt_injection|prompt injection]]-vektorok, vÃ¡ltozÃ³ ellÃ¡tÃ¡si lÃ¡ncok).

A tÃ©rkÃ©pezÃ©s nem adminisztrÃ¡ciÃ³ â€” hanem _helyzetismeret_.  
A tÃ©rkÃ©pnek azt kell tÃ¼krÃ¶znie, ahogyan a tÃ¡madÃ³ gondolkodik: mit lÃ¡t, mit Ã©r el, Ã©s mit kÃ©pes befolyÃ¡solni.

---

## âš™ï¸ Building an AI Threat Map

**EN:**  
The process usually follows the **AI lifecycle**, identifying attack points at every phase:

1. **Data Collection** â€” poisoning, data scraping, and provenance attacks.
    
2. **Data Preparation** â€” [[data_poisoning|Data Poisoning]] and label manipulation.
    
3. **Model Training** â€” [[model_stealing|Model Stealing]] via cloud logs or gradient leakage.
    
4. **Evaluation & Validation** â€” biased metrics and hidden backdoors.
    
5. **Deployment** â€” [[backdoor_and_trojan_attacks|Trojan Activation]] and [[supply_chain_attack|Supply Chain Attack]].
    
6. **Inference** â€” [[membership_inference_attacks|Membership Inference]], [[model_inversion|Model Inversion]], [[prompt_injection_and_rag_attacks|Prompt Injection & RAG Exploits]].
    

Each phase forms a _layer_ in the threat map.  
Together, they show not only how an AI can fail â€” but _when and why_.

**HU:**  
A tÃ©rkÃ©pezÃ©s az **AI Ã©letciklus** logikÃ¡jÃ¡t kÃ¶veti, minden fÃ¡zisban feltÃ¡rva a tÃ¡madÃ¡si pontokat:

1. **AdatgyÅ±jtÃ©s** â€” adatmÃ©rgezÃ©s, scraping, forrÃ¡seredet-manipulÃ¡ciÃ³.
    
2. **AdatelÅ‘kÃ©szÃ­tÃ©s** â€” [[data_poisoning|AdatmÃ©rgezÃ©s]] Ã©s cÃ­mkÃ©zÃ©si manipulÃ¡ciÃ³.
    
3. **ModeltrÃ©ning** â€” [[model_stealing|Modell-lopÃ¡s]] logok vagy gradiens-szivÃ¡rgÃ¡s ÃºtjÃ¡n.
    
4. **Ã‰rtÃ©kelÃ©s Ã©s validÃ¡lÃ¡s** â€” torz metrikÃ¡k, rejtett backdoor-ok.
    
5. **TelepÃ­tÃ©s** â€” [[backdoor_and_trojan_attacks|TrÃ³jai aktivÃ¡lÃ¡s]] Ã©s [[supply_chain_attack|EllÃ¡tÃ¡si lÃ¡nc tÃ¡madÃ¡sok]].
    
6. **Inferencia** â€” [[membership_inference_attacks|TagsÃ¡gi tÃ¡madÃ¡sok]], [[model_inversion|Modell-inverziÃ³]], [[prompt_injection_and_rag_attacks|Prompt Ã©s RAG kihasznÃ¡lÃ¡s]].
    

Minden fÃ¡zis egy _rÃ©teg_ a fenyegetÃ©si tÃ©rkÃ©pen.  
Ezek egyÃ¼tt nemcsak azt mutatjÃ¡k meg, _hogyan_ sÃ©rÃ¼lhet egy AI â€” hanem azt is, _mikor Ã©s miÃ©rt_.

---

## ğŸ§© Layered Understanding of AI Threats

**EN:**  
A strong map doesnâ€™t just list threats â€” it groups them into **conceptual strata**:

- **Data Layer (Input space):** poisoning, leakage, bias.
    
- **Model Layer (Representation space):** backdoors, adversarial examples.
    
- **Runtime Layer (Execution space):** API abuse, sandbox escape, environment takeover.
    
- **Governance Layer (Human space):** policy failure, explainability gaps, unethical deployment.
    

Each layer affects the next.  
For example, a poisoned dataset at layer one can trigger a compliance violation in layer four â€” years later.

**HU:**  
Egy erÅ‘s tÃ©rkÃ©p nemcsak felsorolja a fenyegetÃ©seket â€” hanem **rÃ©tegekbe** rendezi Å‘ket:

- **Adatszint (Bemeneti tÃ©r):** mÃ©rgezÃ©s, szivÃ¡rgÃ¡s, torzÃ­tÃ¡s.
    
- **Modellszint (ReprezentÃ¡ciÃ³s tÃ©r):** backdoor-ok, adversariÃ¡lis mintÃ¡k.
    
- **FuttatÃ¡si szint (VÃ©grehajtÃ¡si tÃ©r):** API-visszaÃ©lÃ©s, sandbox menekÃ¼lÃ©s, kÃ¶rnyezetÃ¡tvÃ©tel.
    
- **IrÃ¡nyÃ­tÃ¡si szint (Emberi tÃ©r):** szabÃ¡lyzÃ¡si hiba, magyarÃ¡zhatÃ³sÃ¡gi hiÃ¡ny, etikÃ¡tlan hasznÃ¡lat.
    

Minden rÃ©teg hat a kÃ¶vetkezÅ‘re.  
PÃ©ldÃ¡ul egy elsÅ‘ rÃ©tegben mÃ©rgezett adathalmaz akÃ¡r Ã©vekkel kÃ©sÅ‘bb negyedik rÃ©tegÅ± megfelelÅ‘sÃ©gi sÃ©rtÃ©st okozhat.

---

## ğŸ§  From Maps to Defense Architecture

**EN:**  
Once mapped, threats become measurable.  
This allows the design of defense architectures that align with the mapâ€™s structure:  
[[defense_index|Defenses]] at the data layer, [[runtime_isolation_and_sandboxing|Isolation]] at runtime, [[continuous_validation_and_review|Continuous Validation]] for governance.

Effective AI threat mapping evolves continuously.  
Itâ€™s not a document â€” itâ€™s a _living neural schema_ for defenders.

**HU:**  
Ha egyszer a fenyegetÃ©seket feltÃ©rkÃ©peztÃ¼k, azok mÃ©rhetÅ‘vÃ© vÃ¡lnak.  
Ez lehetÅ‘vÃ© teszi olyan vÃ©delmi architektÃºrÃ¡k tervezÃ©sÃ©t, amelyek illeszkednek a tÃ©rkÃ©p rÃ©tegeihez:  
[[defense_index|VÃ©delem]] az adatszinten, [[runtime_isolation_and_sandboxing|IzolÃ¡ciÃ³]] a futtatÃ¡si szinten, [[continuous_validation_and_review|Folyamatos validÃ¡lÃ¡s]] az irÃ¡nyÃ­tÃ¡si rÃ©tegben.

A hatÃ©kony AI threat mapping folyamatosan fejlÅ‘dik.  
Nem dokumentum â€” hanem _Ã©lÅ‘ neurÃ¡lis sÃ©ma_ a vÃ©dÅ‘k szÃ¡mÃ¡ra.

---

## âš–ï¸ Linking to MITRE ATLAS and NIST AI RMF

**EN:**  
To operationalize threat mapping, frameworks like [[ai_risk_assessment_methodology|NIST AI RMF]] and MITRE ATLAS provide shared taxonomies.  
They turn abstract concepts into actionable adversarial playbooks â€” describing not just â€œwhat could go wrong,â€ but _how attackers think_.

Using these frameworks in your Vault creates consistency between your theoretical notes and practical red-teaming.

**HU:**  
A fenyegetÃ©s-tÃ©rkÃ©pezÃ©s operacionalizÃ¡lÃ¡sÃ¡hoz olyan keretrendszerek segÃ­tenek, mint a [[ai_risk_assessment_methodology|NIST AI RMF]] Ã©s a MITRE ATLAS.  
Ezek az absztrakt fogalmakat konkrÃ©t tÃ¡madÃ¡si forgatÃ³kÃ¶nyvekkÃ© alakÃ­tjÃ¡k â€” nemcsak azt Ã­rjÃ¡k le, â€mi romolhat elâ€, hanem azt is, _hogyan gondolkodik a tÃ¡madÃ³_.

Ha ezeket a keretrendszereket a Vaultodon belÃ¼l is hasznÃ¡lod, akkor Ã¶sszhang jÃ¶n lÃ©tre az elmÃ©leti jegyzetek Ã©s a gyakorlati red-team tesztek kÃ¶zÃ¶tt.

---

## ğŸ” Review Questions / EllenÅ‘rzÅ‘ kÃ©rdÃ©sek

1. Why must AI threat mapping account for both static and adaptive attack surfaces?
    
2. Which AI lifecycle phase introduces the highest concentration of threats?
    
3. How does layering (data, model, runtime, governance) improve defense design?
    
4. In what way do MITRE ATLAS and NIST AI RMF complement threat mapping?
    
5. How can a living threat map evolve alongside your deployed models?
    

---

> _â€œYou canâ€™t defend what you donâ€™t see â€” and you canâ€™t see what you donâ€™t map.â€_