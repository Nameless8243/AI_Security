---
id: 02_lifecycle
title: "02 â€“ AI Lifecycle / AI Ã©letciklus"
lang: ["hu", "en"]
version: "3.1"
vault: "AI Security Research Vault 2.0"
section_type: "00_Foundations"
role: "lifecycle_analyst"
tags:
  - ai_security
  - foundations
  - underscore_slugs
---
ğŸš¨ COPY START ğŸš¨
# AI System Lifecycle  
*Securing every stage of the modelâ€™s life â€” not just its code*  

---

## ğŸŒ Concept Overview  

**EN:**  
The **AI System Lifecycle** describes the continuous journey of an AI model â€” from **data collection** to **deployment**, **monitoring**, and eventually **retirement**. â™»ï¸  
In classical IT, software is static once deployed. In AI, models evolve, degrade, and must be **constantly retrained and reassessed**.  
Security, therefore, cannot be a single phase â€” it must be an **embedded process across the entire lifecycle**.  

**HU:**  
Az **MI-rendszer Ã©letciklusa** (AI System Lifecycle) az a folyamat, amelyben egy MI-modell **megszÃ¼letik, fejlÅ‘dik, mÅ±kÃ¶dik, majd elavul**. ğŸ”„  
A hagyomÃ¡nyos szoftverekkel ellentÃ©tben az MI nem statikus: a modellek **tanulnak, vÃ¡ltoznak, romlanak**, ezÃ©rt folyamatos karbantartÃ¡st Ã©s felÃ¼gyeletet igÃ©nyelnek.  
A biztonsÃ¡g tehÃ¡t nem egyetlen fÃ¡zis feladata â€” hanem **Ã¡tfogÃ³ folyamat**, amely minden Ã©letciklus-szakaszt vÃ©gigkÃ­sÃ©r.  

---

## ğŸ§© The Six Phases of the AI Lifecycle  

**EN:**  
While different frameworks define the stages differently (e.g., **NIST AI RMF**, **ISO/IEC 42001**, **EU AI Act**), the following six-phase structure captures the essence of secure lifecycle management:  

1. **Data Collection & Ingestion**  
2. **Model Design & Development**  
3. **Training & Validation**  
4. **Deployment & Integration**  
5. **Monitoring & Adaptation**  
6. **Decommissioning & Archival**  

**HU:**  
A kÃ¼lÃ¶nbÃ¶zÅ‘ keretrendszerek (pl. **NIST AI RMF**, **ISO/IEC 42001**, **EU AI Act**) eltÃ©rÅ‘en nevezik a fÃ¡zisokat, de a biztonsÃ¡g szempontjÃ¡bÃ³l hat fÅ‘ szakasz kÃ¼lÃ¶nÃ­thetÅ‘ el:  

1. **AdatgyÅ±jtÃ©s Ã©s beolvasÃ¡s**  
2. **ModelltervezÃ©s Ã©s fejlesztÃ©s**  
3. **TanÃ­tÃ¡s Ã©s validÃ¡lÃ¡s**  
4. **TelepÃ­tÃ©s Ã©s integrÃ¡ciÃ³**  
5. **MegfigyelÃ©s Ã©s alkalmazkodÃ¡s**  
6. **KivezetÃ©s Ã©s archivÃ¡lÃ¡s**  

---

## ğŸ’¡ Phase 1 â€“ Data Collection & Ingestion  

**EN:**  
This phase defines **what the model will learn from**.  
Security controls focus on ensuring **data provenance**, **authenticity**, and **integrity**.  
Techniques like [[data_provenance|Data Provenance]], digital signatures, and schema validation prevent **[[data_poisoning|Data Poisoning]]** or **[[backdoor_and_trojan_attacks|Backdoor Attacks]]**.  

**HU:**  
Ez a fÃ¡zis hatÃ¡rozza meg, **mibÅ‘l tanul** a modell.  
A biztonsÃ¡g itt az **adatok eredetÃ©re, hitelessÃ©gÃ©re Ã©s integritÃ¡sÃ¡ra** Ã¶sszpontosÃ­t.  
Az olyan technikÃ¡k, mint a [[data_provenance|Data Provenance]], a digitÃ¡lis alÃ¡Ã­rÃ¡s Ã©s a sÃ©maellenÅ‘rzÃ©s megakadÃ¡lyozzÃ¡k a **[[data_poisoning|Data Poisoning]]** vagy **[[backdoor_and_trojan_attacks|Backdoor Attacks]]** tÃ­pusÃº tÃ¡madÃ¡sokat.  

---

## ğŸ§  Phase 2 â€“ Model Design & Development  

**EN:**  
During model creation, engineers must consider **attack surfaces** such as overfitting, explainability leakage, or insecure architectures.  
Adopting secure design patterns and **[[threat_modeling_for_ai|Threat Modeling for AI]]** ensures that risks are identified early.  

**HU:**  
A modellfejlesztÃ©s sorÃ¡n a mÃ©rnÃ¶kÃ¶knek figyelembe kell venniÃ¼k a **tÃ¡madÃ¡si felÃ¼leteket**, mint pÃ©ldÃ¡ul a tÃºltanulÃ¡s, a magyarÃ¡zhatÃ³sÃ¡gi szivÃ¡rgÃ¡s vagy a gyenge architektÃºra.  
A biztonsÃ¡gos tervezÃ©si mintÃ¡k Ã©s a **[[threat_modeling_for_ai|Threat Modeling for AI]]** alkalmazÃ¡sa mÃ¡r korai szakaszban azonosÃ­tja a kockÃ¡zatokat.  

---

## âš™ï¸ Phase 3 â€“ Training & Validation  

**EN:**  
Here, the model transforms raw data into learned parameters.  
Security must ensure that training occurs in a **controlled, auditable environment** (e.g., isolated compute nodes, signed model artifacts).  
This phase applies [[differential_privacy|Differential Privacy]], [[adversarial_training|Adversarial Training]], and integrity checks to prevent data leakage and [[membership_inference_attacks|Membership Inference]].  

**HU:**  
Ebben a fÃ¡zisban a modell a nyers adatokat **tanult paramÃ©terekkÃ©** alakÃ­tja.  
A biztonsÃ¡g szempontjÃ¡bÃ³l kulcsfontossÃ¡gÃº, hogy a tanÃ­tÃ¡s **ellenÅ‘rzÃ¶tt, auditÃ¡lhatÃ³ kÃ¶rnyezetben** tÃ¶rtÃ©njen (pl. izolÃ¡lt szÃ¡mÃ­tÃ¡si kÃ¶rnyezet, alÃ¡Ã­rt modellfÃ¡jlok).  
Itt hasznÃ¡lhatÃ³k a [[differential_privacy|Differential Privacy]], az [[adversarial_training|Adversarial Training]] Ã©s az integritÃ¡s-ellenÅ‘rzÃ©sek, hogy elkerÃ¼lhetÅ‘ legyen az adat- vagy tagsÃ¡gi szivÃ¡rgÃ¡s.  

---

## ğŸ›¡ï¸ Phase 4 â€“ Deployment & Integration  

**EN:**  
When a model moves to production, it becomes exposed to real-world inputs â€” and attackers.  
This is where **[[zero_trust_for_ai|Zero Trust for AI]]** becomes critical:  
all APIs, prompts, and data channels must be authenticated, logged, and sandboxed.  
Any inference endpoint should apply **[[input_restoration|Input Restoration]]** to prevent **[[prompt_injection|Prompt Injection]]** or **[[adversarial_example_attacks|Adversarial Example Attacks]]**.  

**HU:**  
A modell Ã©les kÃ¶rnyezetbe kerÃ¼lÃ©sekor **valÃ³s adatoknak Ã©s tÃ¡madÃ³knak** van kitÃ©ve.  
Itt vÃ¡lik lÃ©tfontossÃ¡gÃºvÃ¡ a **[[zero_trust_for_ai|Zero Trust for AI]]** megkÃ¶zelÃ­tÃ©s:  
minden API-t, promptot Ã©s adatcsatornÃ¡t hitelesÃ­teni, naplÃ³zni Ã©s sandboxban futtatni kell.  
Az Ã©rtÃ©kelÃ©si vÃ©gpontokon **[[input_restoration|Input Restoration]]** vÃ©di a modellt a **[[prompt_injection|Prompt Injection]]** Ã©s **[[adversarial_example_attacks|Adversarial Example Attacks]]** ellen.  

---

## ğŸ“Š Phase 5 â€“ Monitoring & Adaptation  

**EN:**  
Once deployed, models begin to **drift** â€” either naturally or maliciously.  
Continuous **[[observability_and_monitoring|Observability]]** ensures that performance, fairness, and trust metrics are tracked in real time.  
A mathematical representation of performance decay over time can be modeled as:  

$$
P(t) = P_0 \cdot e^{-\lambda t}
$$  

where \( P(t) \) is accuracy at time \( t \), \( P_0 \) is initial performance, and \( \lambda \) is the drift rate.  

**HU:**  
A telepÃ­tÃ©s utÃ¡n a modellek **elcsÃºszhatnak** â€“ termÃ©szetes mÃ³don vagy szÃ¡ndÃ©kosan.  
A folyamatos **[[observability_and_monitoring|Observability]]** biztosÃ­tja, hogy a teljesÃ­tmÃ©ny-, fairness- Ã©s bizalmi mutatÃ³k valÃ³s idÅ‘ben kÃ¶vethetÅ‘k legyenek.  
A teljesÃ­tmÃ©ny idÅ‘beli romlÃ¡sa modellezhetÅ‘ pÃ©ldÃ¡ul Ã­gy:  

$$
P(t) = P_0 \cdot e^{-\lambda t}
$$  

ahol \( P(t) \) az aktuÃ¡lis pontossÃ¡g, \( P_0 \) a kezdeti teljesÃ­tmÃ©ny, \( \lambda \) pedig a drift sebessÃ©ge.  

---

## ğŸª¦ Phase 6 â€“ Decommissioning & Archival  

**EN:**  
Every model must eventually be **retired**, especially when it becomes outdated, untrustworthy, or legally non-compliant.  
Secure decommissioning includes:  
- deleting sensitive training data,  
- revoking model credentials,  
- and cryptographically archiving audit logs for traceability.  

**HU:**  
Minden modellt elÅ‘bb-utÃ³bb **ki kell vezetni**, kÃ¼lÃ¶nÃ¶sen ha elavult, megbÃ­zhatatlan vagy nem felel meg a jogszabÃ¡lyoknak.  
A biztonsÃ¡gos kivezetÃ©s tartalmazza:  
- az Ã©rzÃ©keny tanÃ­tÃ³adatok tÃ¶rlÃ©sÃ©t,  
- a modellhez tartozÃ³ hitelesÃ­tÃ©si kulcsok visszavonÃ¡sÃ¡t,  
- Ã©s az auditnaplÃ³k **kriptogrÃ¡fiai archivÃ¡lÃ¡sÃ¡t** az Ã¡tlÃ¡thatÃ³sÃ¡g Ã©rdekÃ©ben.  

---

## âš–ï¸ Governance and Lifecycle Assurance  

**EN:**  
Lifecycle security aligns with governance frameworks like **[[ai_governance|AI Governance]]** and **NIST AI RMF**.  
Each phase must produce **evidence artifacts** â€” signed datasets, validation reports, risk registers â€” that prove compliance and integrity.  
Security is not a checkpoint; itâ€™s a continuous thread woven through every lifecycle stage.  

**HU:**  
Az Ã©letciklus-biztonsÃ¡g Ã¶sszhangban van az olyan keretrendszerekkel, mint az **[[ai_governance|AI Governance]]** Ã©s a **NIST AI RMF**.  
Minden fÃ¡zisnak **bizonyÃ­tÃ©kokat** kell termelnie â€“ alÃ¡Ã­rt adatokat, validÃ¡lÃ¡si jegyzÅ‘kÃ¶nyveket, kockÃ¡zati nyilvÃ¡ntartÃ¡sokat â€“ amelyek igazoljÃ¡k a megfelelÃ©st Ã©s az integritÃ¡st.  
A biztonsÃ¡g nem ellenÅ‘rzÅ‘pont, hanem **folyamatos szÃ¡l**, amely Ã¡tszÃ¶vi az egÃ©sz Ã©letciklust.  

---

## ğŸ§© Related Vault Topics  

- [[data_provenance|Data Provenance]]  
- [[model_drift|Model Drift]]  
- [[zero_trust_for_ai|Zero Trust for AI]]  
- [[input_restoration|Input Restoration]]  
- [[observability_and_monitoring|Observability and Monitoring]]  
- [[ai_governance|AI Governance]]  

---

## ğŸ§­ Review Questions / EllenÅ‘rzÅ‘ kÃ©rdÃ©sek  

1. **EN:** Why must AI security be embedded across all lifecycle phases instead of treated as a separate step?  
   **HU:** MiÃ©rt kell az MI-biztonsÃ¡got az egÃ©sz Ã©letciklusba beÃ©pÃ­teni, nem pedig kÃ¼lÃ¶n szakaszkÃ©nt kezelni?  

2. **EN:** What are the primary risks during the data collection and training phases?  
   **HU:** Mik a legfÅ‘bb kockÃ¡zatok az adatgyÅ±jtÃ©s Ã©s tanÃ­tÃ¡s fÃ¡zisÃ¡ban?  

3. **EN:** How does Zero Trust apply to model deployment and API exposure?  
   **HU:** Hogyan alkalmazhatÃ³ a Zero Trust elv a modell telepÃ­tÃ©sÃ©re Ã©s az API-k biztonsÃ¡gÃ¡ra?  

4. **EN:** How can continuous observability detect malicious drift in production?  
   **HU:** Hogyan segÃ­t a folyamatos megfigyelÃ©s felismerni a rosszindulatÃº driftet az Ã©les kÃ¶rnyezetben?  

5. **EN:** What are the key security tasks during model decommissioning?  
   **HU:** Mik a legfontosabb biztonsÃ¡gi feladatok a modell kivezetÃ©sekor?  

---

> â€œA secure AI is not born secure â€” it becomes secure through every stage of its life.â€ ğŸ”  

ğŸš¨ COPY END ğŸš¨
