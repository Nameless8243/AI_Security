---
id: 00_index
title: "00 â€“ Foundations Index"
lang: ["hu", "en"]
version: "3.1"
vault: "AI Security Research Vault 2.0"
section_type: "00_Foundations"
role: "index_architect"
tags:
  - ai_security
  - foundations
  - underscore_slugs
---
ğŸš¨ COPY START ğŸš¨
# 00_Foundations â€“ Index  
*Building the mental architecture of AI Security*  

---

## ğŸŒ Purpose of the Foundations Section  

**EN:**  
This section establishes the **core knowledge base** for understanding and securing Artificial Intelligence systems.  
Before analyzing complex attacks or defense strategies, one must understand the *foundations* â€” how models learn, how data flows, what trust means, and how security, privacy, and governance intersect. ğŸ§   

**HU:**  
Ez a fejezet az **alapvetÅ‘ ismereteket** foglalja Ã¶ssze, amelyek nÃ©lkÃ¼l nem Ã©rthetÅ‘ meg a mestersÃ©ges intelligencia biztonsÃ¡ga.  
MielÅ‘tt a tÃ¡madÃ¡sokat vagy vÃ©delmi mÃ³dszereket tanulnÃ¡nk, elÅ‘bb meg kell Ã©rteni az **alapokat** â€“ hogyan tanulnak a modellek, hogyan Ã¡ramlik az adat, mit jelent a bizalom, Ã©s hogyan kapcsolÃ³dik Ã¶ssze a biztonsÃ¡g, az adatvÃ©delem Ã©s az irÃ¡nyÃ­tÃ¡s. ğŸ”’  

---

## ğŸ§© Core Concepts  

**EN:**  
Each of the following glossary entries provides a conceptual brick in the foundation of AI Security.  
Together, they explain *how trust, control, and adaptation* define the resilience of AI systems:  

- [[explainability|Explainability]] ğŸ§  â€“ understanding why the model makes a decision.  
- [[interpretability|Interpretability]] ğŸ” â€“ understanding how the model makes it.  
- [[input_restoration|Input Restoration]] ğŸ§¼ â€“ purifying incoming data before it harms the model.  
- [[membership_inference_attacks|Membership Inference]] ğŸ•µï¸â€â™‚ï¸ â€“ when outputs reveal who was part of training.  
- [[model_drift|Model Drift]] â³ â€“ when a model loses alignment with reality.  
- [[prompt_injection|Prompt Injection]] ğŸ§© â€“ when adversaries hijack the modelâ€™s instructions.  
- [[zero_trust_for_ai|Zero Trust for AI]] ğŸ›¡ï¸ â€“ trust nothing, verify everything.  
- [[data_provenance|Data Provenance]] ğŸ—‚ï¸ â€“ ensuring the authenticity and traceability of data.  
- [[fairness|Fairness]] âš–ï¸ â€“ preventing bias in model decisions.  
- [[ai_governance|AI Governance]] ğŸ›ï¸ â€“ ensuring responsible, transparent oversight.  

**HU:**  
A kÃ¶vetkezÅ‘ fogalmak az MI-biztonsÃ¡g Ã©pÃ­tÅ‘kockÃ¡i, amelyek egyÃ¼tt meghatÃ¡rozzÃ¡k a **bizalom, kontroll Ã©s alkalmazkodÃ¡s** rendszerÃ©t:  

- [[explainability|Explainability]] ğŸ§  â€“ miÃ©rt dÃ¶nt Ã­gy a modell.  
- [[interpretability|Interpretability]] ğŸ” â€“ hogyan dÃ¶nt a modell.  
- [[input_restoration|Input Restoration]] ğŸ§¼ â€“ a bemeneti adatok megtisztÃ­tÃ¡sa a kÃ¡ros hatÃ¡sok elÅ‘tt.  
- [[membership_inference_attacks|Membership Inference]] ğŸ•µï¸â€â™‚ï¸ â€“ amikor a kimenetbÅ‘l kikÃ¶vetkeztethetÅ‘, ki szerepelt a tanÃ­tÃ³halmazban.  
- [[model_drift|Model Drift]] â³ â€“ amikor a modell elcsÃºszik a valÃ³sÃ¡gtÃ³l.  
- [[prompt_injection|Prompt Injection]] ğŸ§© â€“ amikor a tÃ¡madÃ³k Ã¡tveszik az irÃ¡nyÃ­tÃ¡st a modell utasÃ­tÃ¡sai felett.  
- [[zero_trust_for_ai|Zero Trust for AI]] ğŸ›¡ï¸ â€“ ne bÃ­zz meg semmiben, mindig ellenÅ‘rizz.  
- [[data_provenance|Data Provenance]] ğŸ—‚ï¸ â€“ az adatok eredetÃ©nek Ã©s hitelessÃ©gÃ©nek biztosÃ­tÃ¡sa.  
- [[fairness|Fairness]] âš–ï¸ â€“ az elfogultsÃ¡g elkerÃ¼lÃ©se a modellek dÃ¶ntÃ©seiben.  
- [[ai_governance|AI Governance]] ğŸ›ï¸ â€“ az MI rendszerek felelÅ‘s Ã©s Ã¡tlÃ¡thatÃ³ felÃ¼gyelete.  

---

## ğŸ’¡ How the Foundations Interconnect  

**EN:**  
These concepts form an **interdependent network**:  
- Without **Explainability**, you canâ€™t audit decisions.  
- Without **Zero Trust**, you canâ€™t secure the data or the model.  
- Without **Input Restoration**, you canâ€™t rely on any analysis.  
- Without **Governance**, you canâ€™t ensure accountability or compliance.  

This foundation therefore serves as both the *educational entry point* and the *philosophical spine* of the entire Vault.  

**HU:**  
Ezek a fogalmak **Ã¶sszefÃ¼ggÅ‘ hÃ¡lÃ³zatot** alkotnak:  
- **Explainability** nÃ©lkÃ¼l nem lehet auditÃ¡lni a dÃ¶ntÃ©seket.  
- **Zero Trust** nÃ©lkÃ¼l nem biztosÃ­thatÃ³ sem az adat, sem a modell.  
- **Input Restoration** nÃ©lkÃ¼l semmilyen elemzÃ©s nem megbÃ­zhatÃ³.  
- **Governance** nÃ©lkÃ¼l nincs elszÃ¡moltathatÃ³sÃ¡g vagy megfelelÃ©s.  

Ez a fejezet tehÃ¡t egyszerre **tanulÃ¡si belÃ©pÅ‘pont** Ã©s az egÃ©sz Vault **filozÃ³fiai gerince**.  

---

## âš™ï¸ Mathematical and Logical Foundations  

**EN:**  
Many foundational concepts of AI Security are grounded in mathematics and logic â€” they define what â€œtrustâ€ means in quantifiable terms.  

For example, drift or model decay can be represented as a distance metric \( D \) between training and production distributions:  

$$
D = \lVert P_{\text{train}}(X, Y) - P_{\text{prod}}(X, Y) \rVert
$$  

Similarly, Zero Trust confidence scores evolve according to observed anomalies \( A_t \):  

$$
T_{t+1} = T_t \cdot e^{-\lambda A_t}
$$  

**HU:**  
Az MI-biztonsÃ¡g alapfogalmai **matematikai Ã©s logikai elveken** nyugszanak â€“ szÃ¡mszerÅ±sÃ­tik a â€bizalmatâ€.  

PÃ©ldÃ¡ul a drift (modell elcsÃºszÃ¡s) mÃ©rhetÅ‘ a tanÃ­tÃ³ Ã©s Ã©les eloszlÃ¡s kÃ¶zti tÃ¡volsÃ¡ggal \( D \):  

$$
D = \lVert P_{\text{train}}(X, Y) - P_{\text{prod}}(X, Y) \rVert
$$  

HasonlÃ³an, a Zero Trust bizalmi Ã©rtÃ©k idÅ‘ben vÃ¡ltozik az anomÃ¡liÃ¡k fÃ¼ggvÃ©nyÃ©ben \( A_t \):  

$$
T_{t+1} = T_t \cdot e^{-\lambda A_t}
$$  

---

## ğŸ§  Why â€œFoundationsâ€ Matter in AI Security  

**EN:**  
In AI security, failure rarely begins with a hack â€” it begins with **a wrong assumption**.  
Foundational understanding eliminates these weak assumptions by making every concept explicit, measurable, and traceable.  
It connects the human mindset (ethics, governance) with the machine logic (models, data, and trust).  

**HU:**  
Az MI-biztonsÃ¡gban a hibÃ¡k ritkÃ¡n valÃ³di hackelÃ©ssel kezdÅ‘dnek â€” Ã¡ltalÃ¡ban egy **rossz feltÃ©telezÃ©ssel**.  
Az alapok megÃ©rtÃ©se megszÃ¼nteti ezeket a gyenge pontokat azÃ¡ltal, hogy minden fogalmat **kifejezettÃ©, mÃ©rhetÅ‘vÃ© Ã©s visszakÃ¶vethetÅ‘vÃ©** tesz.  
Ã–sszekapcsolja az emberi gondolkodÃ¡st (etika, irÃ¡nyÃ­tÃ¡s) a gÃ©pi logikÃ¡val (modellek, adatok, bizalom).  

---

## ğŸ§© Related Vault Topics  

- [[01_Attack_Taxonomy_and_Threats/00_index|Attack Taxonomy and Threats â€“ Index]]  
- [[02_Defenses_and_Mitigations/00_index|Defenses and Mitigations â€“ Index]]  
- [[05_AI_Risk_Management_and_Assurance/00_index|AI Risk Management and Assurance â€“ Index]]  
- [[06_AI_Safety_and_Ethical_Assurance/00_index|AI Safety and Ethics â€“ Index]]  

---

## ğŸ§­ Review Questions / EllenÅ‘rzÅ‘ kÃ©rdÃ©sek  

1. **EN:** Why must every AI security study begin with the foundational concepts?  
   **HU:** MiÃ©rt kell az MI-biztonsÃ¡g tanulÃ¡sÃ¡t az alapfogalmaknÃ¡l kezdeni?  

2. **EN:** How do explainability and interpretability complement each other?  
   **HU:** Hogyan egÃ©szÃ­ti ki egymÃ¡st az explainability Ã©s az interpretability?  

3. **EN:** Why is Zero Trust considered the â€œsecurity philosophyâ€ of AI systems?  
   **HU:** MiÃ©rt tekintik a Zero Trust-ot az MI-rendszerek â€biztonsÃ¡gi filozÃ³fiÃ¡jÃ¡nakâ€?  

4. **EN:** How does model drift demonstrate the need for continuous monitoring?  
   **HU:** Hogyan szemlÃ©lteti a modelldrift a folyamatos megfigyelÃ©s szÃ¼ksÃ©gessÃ©gÃ©t?  

5. **EN:** What connects fairness, governance, and trust in AI Security foundations?  
   **HU:** Mi kÃ¶ti Ã¶ssze a fairness, governance Ã©s trust fogalmakat az MI-biztonsÃ¡g alapjaiban?  

---

> â€œStrong systems are built on clear concepts. Weak ones are built on assumptions.â€ ğŸ§±  

ğŸš¨ COPY END ğŸš¨
