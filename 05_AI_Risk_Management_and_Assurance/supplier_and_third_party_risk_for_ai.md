---
version: "3.2"
section_type: "risk"
agent: "Lifecycle Analyst"
---
---
title: Supplier and Third-Party Risk for AI
phase: Governance
category: Supply Chain Assurance
difficulty: Advanced
related: [ai_supply_chain_attestation_and_audit, ai_sbom_and_mbom_management, regulatory_and_legal_compliance, ai_risk_assessment_methodology, model_risk_management_and_registers]
updated: 2025-11-10
---

# ğŸŒ Supplier and Third-Party Risk for AI / BeszÃ¡llÃ­tÃ³i Ã©s harmadik fÃ©ltÅ‘l szÃ¡rmazÃ³ kockÃ¡zatok az MI-ben

**EN:**  
AI systems rarely exist in isolation â€” they rely on a complex ecosystem of **vendors, APIs, models, and cloud services**.  
Each external dependency introduces potential weaknesses that can undermine the systemâ€™s integrity, privacy, or compliance posture.  
Supplier and third-party risk management ensures that the **trust you build internally is not lost externally**.  

**HU:**  
Az MI-rendszerek ritkÃ¡n mÅ±kÃ¶dnek elszigetelten â€” **szÃ¡llÃ­tÃ³k, API-k, modellek Ã©s felhÅ‘szolgÃ¡ltatÃ¡sok** Ã¶sszetett Ã¶koszisztÃ©mÃ¡jÃ¡ra Ã©pÃ¼lnek.  
Minden kÃ¼lsÅ‘ fÃ¼ggÅ‘sÃ©g potenciÃ¡lis gyengesÃ©get jelenthet, amely veszÃ©lyeztetheti a rendszer integritÃ¡sÃ¡t, adatvÃ©delmÃ©t vagy megfelelÅ‘sÃ©gÃ©t.  
A beszÃ¡llÃ­tÃ³i Ã©s harmadik fÃ©ltÅ‘l szÃ¡rmazÃ³ kockÃ¡zatkezelÃ©s cÃ©lja, hogy a **belsÅ‘leg felÃ©pÃ­tett bizalom ne vesszen el a kÃ¼lsÅ‘ hatÃ¡rokon**. ğŸ§©  

---

## ğŸŒ Concept Overview / Fogalmi Ã¡ttekintÃ©s

**EN:**  
Supplier and third-party risk management (TPRM) for AI is the process of **evaluating, monitoring, and governing** all external entities that contribute to an AI systemâ€™s lifecycle.  
This includes:
- Cloud and infrastructure providers,  
- AI model vendors or pretrained model sources,  
- Data suppliers and labeling vendors,  
- Open-source libraries and API dependencies.  

**HU:**  
Az MI-hez kapcsolÃ³dÃ³ beszÃ¡llÃ­tÃ³i Ã©s harmadik fÃ©ltÅ‘l szÃ¡rmazÃ³ kockÃ¡zatkezelÃ©s (TPRM) az Ã¶sszes **kÃ¼lsÅ‘ entitÃ¡s Ã©rtÃ©kelÃ©sÃ©t, megfigyelÃ©sÃ©t Ã©s irÃ¡nyÃ­tÃ¡sÃ¡t** jelenti, amely rÃ©szt vesz az MI-rendszer Ã©letciklusÃ¡ban.  
Ide tartoznak:  
- a felhÅ‘- Ã©s infrastruktÃºraszolgÃ¡ltatÃ³k,  
- az MI-modellbeszÃ¡llÃ­tÃ³k Ã©s elÅ‘tanÃ­tott modellek forrÃ¡sai,  
- az adatbeszÃ¡llÃ­tÃ³k Ã©s cÃ­mkÃ©zÅ‘ vÃ¡llalkozÃ³k,  
- a nyÃ­lt forrÃ¡sÃº kÃ¶nyvtÃ¡rak Ã©s API-fÃ¼ggÅ‘sÃ©gek. âš™ï¸  

---

## ğŸ’¡ Core Idea / Alapgondolat

**EN:**  
Third-party trust is **not transferable** â€” each supplier must provide verifiable assurance.  
AI security extends beyond your code and data; it includes **the entire ecosystem** that influences your modelâ€™s behavior and governance posture.  
The goal of TPRM is to make this web of dependencies **transparent, auditable, and contractually accountable**.  

**HU:**  
A harmadik fÃ©ltÅ‘l szÃ¡rmazÃ³ bizalom **nem Ã¡truhÃ¡zhatÃ³** â€” minden beszÃ¡llÃ­tÃ³nak ellenÅ‘rizhetÅ‘ garanciÃ¡t kell nyÃºjtania.  
Az MI-biztonsÃ¡g nem korlÃ¡tozÃ³dik a sajÃ¡t kÃ³dodra Ã©s adataidra; magÃ¡ban foglalja **az egÃ©sz Ã¶koszisztÃ©mÃ¡t**, amely befolyÃ¡solja a modell viselkedÃ©sÃ©t Ã©s irÃ¡nyÃ­tÃ¡si helyzetÃ©t.  
A TPRM cÃ©lja, hogy ez a fÃ¼ggÅ‘sÃ©gi hÃ¡lÃ³ **Ã¡tlÃ¡thatÃ³, auditÃ¡lhatÃ³ Ã©s szerzÅ‘dÃ©sileg elszÃ¡moltathatÃ³** legyen. ğŸ”  

---

## ğŸ§± Risk Categories / KockÃ¡zati kategÃ³riÃ¡k

**EN:**  
Third-party risks in AI can be grouped into:
1. **Data Risks:** provenance, accuracy, licensing, and privacy.  
2. **Model Risks:** quality, robustness, and vulnerability of pretrained models.  
3. **Infrastructure Risks:** cloud configuration, shared responsibility, and key management.  
4. **Compliance Risks:** missing documentation or regulatory misalignment.  
5. **Ethical Risks:** opacity, bias inheritance, and social impact from external inputs.  

**HU:**  
Az MI-hez kapcsolÃ³dÃ³ harmadik fÃ©ltÅ‘l szÃ¡rmazÃ³ kockÃ¡zatok az alÃ¡bbi csoportokba sorolhatÃ³k:  
1. **AdatkockÃ¡zatok:** szÃ¡rmazÃ¡s, pontossÃ¡g, licencelÃ©s, adatvÃ©delem.  
2. **ModellkockÃ¡zatok:** elÅ‘tanÃ­tott modellek minÅ‘sÃ©ge, robusztussÃ¡ga Ã©s sebezhetÅ‘sÃ©ge.  
3. **InfrastrukturÃ¡lis kockÃ¡zatok:** felhÅ‘konfigurÃ¡ciÃ³, megosztott felelÅ‘ssÃ©g, kulcskezelÃ©s.  
4. **MegfelelÅ‘sÃ©gi kockÃ¡zatok:** hiÃ¡nyzÃ³ dokumentÃ¡ciÃ³ vagy szabÃ¡lyozÃ¡si eltÃ©rÃ©s.  
5. **Etikai kockÃ¡zatok:** Ã¡tlÃ¡thatatlansÃ¡g, Ã¶rÃ¶kÃ¶lt torzÃ­tÃ¡sok, kÃ¼lsÅ‘ hatÃ¡sok tÃ¡rsadalmi kÃ¶vetkezmÃ©nyei. ğŸŒ  

---

## âš™ï¸ Evaluation and Due Diligence / Ã‰rtÃ©kelÃ©s Ã©s Ã¡tvilÃ¡gÃ­tÃ¡s

**EN:**  
A supplierâ€™s trustworthiness must be proven, not assumed.  
Before integration, organizations should:
1. Request **security and compliance certifications** (ISO 27001, SOC 2, ISO 42001).  
2. Evaluate **AI-specific risks** â€” data lineage, model explainability, fairness.  
3. Require **SBOM/MBOM disclosures** ([[ai_sbom_and_mbom_management]]).  
4. Validate **PKI-based signing** for data, models, and APIs ([[model_release_and_signing]]).  
5. Assess **incident response maturity** and SLAs.  

**HU:**  
A beszÃ¡llÃ­tÃ³ megbÃ­zhatÃ³sÃ¡gÃ¡t **bizonyÃ­tani kell, nem feltÃ©telezni**.  
IntegrÃ¡ciÃ³ elÅ‘tt a szervezetnek:  
1. BizonyÃ­tania kell a **biztonsÃ¡gi Ã©s megfelelÅ‘sÃ©gi tanÃºsÃ­tvÃ¡nyokat** (ISO 27001, SOC 2, ISO 42001).  
2. Ã‰rtÃ©kelnie kell az **MI-specifikus kockÃ¡zatokat** â€” adatszÃ¡rmazÃ¡s, magyarÃ¡zhatÃ³sÃ¡g, mÃ©ltÃ¡nyossÃ¡g.  
3. KÃ¶vetelnie kell az **SBOM/MBOM-leltÃ¡rak** kÃ¶zzÃ©tÃ©telÃ©t ([[ai_sbom_and_mbom_management]]).  
4. EllenÅ‘riznie kell az **PKI-alapÃº alÃ¡Ã­rÃ¡sokat** az adatokra, modellekre Ã©s API-kra ([[model_release_and_signing]]).  
5. Fel kell mÃ©rnie az **incidenskezelÃ©si Ã©rettsÃ©get** Ã©s a szolgÃ¡ltatÃ¡si szintmegÃ¡llapodÃ¡sokat (SLA). ğŸ§¾  

---

## ğŸ§© Continuous Monitoring / Folyamatos megfigyelÃ©s

**EN:**  
Third-party risk does not end after onboarding.  
It must be **continuously monitored** through:
- Vulnerability feeds and threat intelligence updates.  
- Contract compliance audits.  
- AI supply chain attestation systems ([[ai_supply_chain_attestation_and_audit]]).  
- Model performance drift tracking using external components ([[model_integrity_monitoring]]).  

**HU:**  
A harmadik fÃ©ltÅ‘l szÃ¡rmazÃ³ kockÃ¡zat nem Ã©r vÃ©get a beszÃ¡llÃ­tÃ³ belÃ©ptetÃ©sÃ©vel.  
**Folyamatosan figyelni kell** a kÃ¶vetkezÅ‘ mÃ³dokon:  
- SÃ©rÃ¼lÃ©kenysÃ©gi Ã©s fenyegetÃ©si hÃ­rcsatornÃ¡k monitorozÃ¡sa.  
- SzerzÅ‘dÃ©ses megfelelÅ‘sÃ©gi auditok vÃ©grehajtÃ¡sa.  
- MI-ellÃ¡tÃ¡si lÃ¡nc hitelesÃ­tÃ©si rendszerek alkalmazÃ¡sa ([[ai_supply_chain_attestation_and_audit]]).  
- A modell teljesÃ­tmÃ©nysodrÃ³dÃ¡sÃ¡nak figyelÃ©se a kÃ¼lsÅ‘ komponensek hatÃ¡sÃ¡ra ([[model_integrity_monitoring]]). ğŸ”„  

---

## ğŸ” Contractual and Governance Controls / SzerzÅ‘dÃ©ses Ã©s irÃ¡nyÃ­tÃ¡si kontrollok

**EN:**  
Strong TPRM integrates legal and governance enforcement:
- Include **AI-specific SLAs** in supplier contracts (bias limits, retraining cadence).  
- Require **attestation evidence** for all externally sourced AI components.  
- Establish **termination clauses** for non-compliance or data integrity breaches.  
- Maintain a **Third-Party Risk Register** linked to the overall [[model_risk_management_and_registers]].  

**HU:**  
A hatÃ©kony TPRM jogi Ã©s irÃ¡nyÃ­tÃ¡si Ã©rvÃ©nyesÃ­tÃ©st is tartalmaz:  
- Tartalmazzon a szerzÅ‘dÃ©s **MI-specifikus SLA-kat** (torzÃ­tÃ¡si hatÃ¡rok, ÃºjratanÃ­tÃ¡si gyakorisÃ¡g).  
- KÃ¶vetelje meg **hitelesÃ­tÃ©si bizonyÃ­tÃ©kok** benyÃºjtÃ¡sÃ¡t minden kÃ¼lsÅ‘ MI-komponensre.  
- RÃ¶gzÃ­tsen **felmondÃ¡si zÃ¡radÃ©kokat** a megfelelÃ©s megsÃ©rtÃ©se vagy adatintegritÃ¡si incidens esetÃ©re.  
- Tartson fenn **Harmadik Felek KockÃ¡zati NyilvÃ¡ntartÃ¡st**, amely kapcsolÃ³dik az Ã¡ltalÃ¡nos [[model_risk_management_and_registers]] rendszerhez. âš–ï¸  

---

## âš–ï¸ Regulatory and Ethical Context / SzabÃ¡lyozÃ¡si Ã©s etikai kontextus

**EN:**  
Third-party accountability is embedded in multiple frameworks:  
- **EU AI Act (Art. 28â€“30):** suppliers must ensure traceability and conformity.  
- **ISO/IEC 42001:** requires vendor assessment and lifecycle control.  
- **NIST AI RMF:** â€œManageâ€ function â€” external party alignment.  
- **OECD AI Principles:** shared accountability and responsible sourcing.  

**HU:**  
A harmadik fÃ©l felelÅ‘ssÃ©gvÃ¡llalÃ¡sa tÃ¶bb szabvÃ¡nyban is megjelenik:  
- **EU AI Act (28â€“30. cikk):** a beszÃ¡llÃ­tÃ³knak biztosÃ­taniuk kell a visszakÃ¶vethetÅ‘sÃ©get Ã©s a megfelelÃ©st.  
- **ISO/IEC 42001:** megkÃ¶veteli a beszÃ¡llÃ­tÃ³i Ã©rtÃ©kelÃ©st Ã©s az Ã©letciklus-kontrollt.  
- **NIST AI RMF:** â€Manageâ€ funkciÃ³ â€” kÃ¼lsÅ‘ felek Ã¶sszehangolÃ¡sa.  
- **OECD MI-elvek:** kÃ¶zÃ¶s felelÅ‘ssÃ©g Ã©s etikus beszerzÃ©s. ğŸŒ  

---

## ğŸš€ Future Directions / JÃ¶vÅ‘beli irÃ¡nyok

**EN:**  
Future AI supply ecosystems will adopt **verifiable third-party credentials** â€” cryptographically signed supplier attestations proving compliance and ethical sourcing.  
AI agents may autonomously evaluate supplier reliability through real-time API risk scoring.  
Ultimately, supply chains will evolve into **self-auditing trust networks**.  

**HU:**  
A jÃ¶vÅ‘ MI-ellÃ¡tÃ¡si Ã¶koszisztÃ©mÃ¡i **hitelesÃ­tett, kriptogrÃ¡fiailag alÃ¡Ã­rt beszÃ¡llÃ­tÃ³i tanÃºsÃ­tvÃ¡nyokat** fognak hasznÃ¡lni, amelyek bizonyÃ­tjÃ¡k a megfelelÃ©st Ã©s az etikus forrÃ¡sokat.  
Az MI-Ã¼gynÃ¶kÃ¶k valÃ³s idÅ‘ben Ã©rtÃ©kelhetik a beszÃ¡llÃ­tÃ³k megbÃ­zhatÃ³sÃ¡gÃ¡t **API-alapÃº kockÃ¡zati pontszÃ¡mÃ­tÃ¡s** segÃ­tsÃ©gÃ©vel.  
VÃ©gÃ¼l az ellÃ¡tÃ¡si lÃ¡ncok **Ã¶nellenÅ‘rzÅ‘ bizalmi hÃ¡lÃ³zatokkÃ¡** fejlÅ‘dnek. ğŸ¤–  

---

## ğŸ§­ Review Questions / EllenÅ‘rzÅ‘ kÃ©rdÃ©sek

1. What are the main categories of third-party risk in AI systems?  
2. How can SBOM/MBOM management support supplier transparency?  
3. Why is PKI-based attestation critical for external model trust?  
4. What continuous monitoring practices reduce third-party exposure?  
5. How do contractual clauses enforce AI governance requirements?  
6. Which global frameworks mandate vendor accountability?  
7. How might AI-driven risk scoring transform future TPRM?  

---

> â€œTrust in AI is only as strong as the weakest supplier in its chain.â€
